{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9ff5c0-752d-4c77-86b9-9d7c85a4f0d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-1.2.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langchain-core\n",
      "  Using cached langchain_core-1.2.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.2 (from langchain)\n",
      "  Downloading langgraph-1.0.5-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core)\n",
      "  Downloading langsmith-0.6.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core)\n",
      "  Using cached uuid_utils-0.12.0-cp39-abi3-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_sdk-0.3.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading ormsgpack-1.12.1-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached orjson-3.11.5-cp313-cp313-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Downloading zstandard-0.25.0-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.41.5-cp313-cp313-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
      "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community)\n",
      "  Downloading sqlalchemy-2.0.45-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.13.3-cp313-cp313-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting numpy>=2.1.0 (from langchain-community)\n",
      "  Downloading numpy-2.4.0-cp313-cp313-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.8.0-cp313-cp313-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.7.0-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.4.1-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.22.0-cp313-cp313-win_amd64.whl.metadata (77 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.6.3)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community)\n",
      "  Downloading greenlet-3.3.0-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-1.2.1-py3-none-any.whl (105 kB)\n",
      "Using cached langchain_core-1.2.6-py3-none-any.whl (489 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langgraph-1.0.5-py3-none-any.whl (157 kB)\n",
      "Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_sdk-0.3.1-py3-none-any.whl (66 kB)\n",
      "Downloading langsmith-0.6.1-py3-none-any.whl (282 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.0/2.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 4.3 MB/s  0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached uuid_utils-0.12.0-cp39-abi3-win_amd64.whl (183 kB)\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.8/2.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.6/2.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 3.7 MB/s  0:00:00\n",
      "Downloading aiohttp-3.13.3-cp313-cp313-win_amd64.whl (453 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 4.8 MB/s  0:00:00\n",
      "Downloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.7.0-cp313-cp313-win_amd64.whl (45 kB)\n",
      "Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Downloading sqlalchemy-2.0.45-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 1.0/2.1 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.2 MB/s  0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.22.0-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading frozenlist-1.8.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Downloading greenlet-3.3.0-cp313-cp313-win_amd64.whl (301 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading numpy-2.4.0-cp313-cp313-win_amd64.whl (12.3 MB)\n",
      "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/12.3 MB 6.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.8/12.3 MB 4.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.9/12.3 MB 4.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.7/12.3 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.5/12.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.3 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.0/12.3 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.8/12.3 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.6/12.3 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.4/12.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.3 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.0/12.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.7/12.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.5/12.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.3/12.3 MB 3.9 MB/s  0:00:03\n",
      "Using cached orjson-3.11.5-cp313-cp313-win_amd64.whl (133 kB)\n",
      "Downloading ormsgpack-1.12.1-cp313-cp313-win_amd64.whl (116 kB)\n",
      "Downloading propcache-0.4.1-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Downloading zstandard-0.25.0-cp313-cp313-win_amd64.whl (506 kB)\n",
      "Installing collected packages: zstandard, xxhash, uuid-utils, typing-inspection, tenacity, python-dotenv, pydantic-core, propcache, ormsgpack, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpatch, httpx-sse, greenlet, frozenlist, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests-toolbelt, pydantic, aiosignal, pydantic-settings, langsmith, langgraph-sdk, dataclasses-json, aiohttp, langchain-core, langgraph-checkpoint, langchain-text-splitters, langgraph-prebuilt, langchain-classic, langgraph, langchain-community, langchain\n",
      "\n",
      "   ----------------------------------------  0/39 [zstandard]\n",
      "   -- -------------------------------------  2/39 [uuid-utils]\n",
      "   --- ------------------------------------  3/39 [typing-inspection]\n",
      "   ---- -----------------------------------  4/39 [tenacity]\n",
      "   ---- -----------------------------------  4/39 [tenacity]\n",
      "   ---- -----------------------------------  4/39 [tenacity]\n",
      "   ---- -----------------------------------  4/39 [tenacity]\n",
      "   ----- ----------------------------------  5/39 [python-dotenv]\n",
      "   ----- ----------------------------------  5/39 [python-dotenv]\n",
      "   ----- ----------------------------------  5/39 [python-dotenv]\n",
      "   ------ ---------------------------------  6/39 [pydantic-core]\n",
      "   ------ ---------------------------------  6/39 [pydantic-core]\n",
      "   ------- --------------------------------  7/39 [propcache]\n",
      "   -------- -------------------------------  8/39 [ormsgpack]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ------------ --------------------------- 12/39 [multidict]\n",
      "   ------------ --------------------------- 12/39 [multidict]\n",
      "   ------------- -------------------------- 13/39 [marshmallow]\n",
      "   ------------- -------------------------- 13/39 [marshmallow]\n",
      "   ------------- -------------------------- 13/39 [marshmallow]\n",
      "   ------------- -------------------------- 13/39 [marshmallow]\n",
      "   -------------- ------------------------- 14/39 [jsonpatch]\n",
      "   --------------- ------------------------ 15/39 [httpx-sse]\n",
      "   ---------------- ----------------------- 16/39 [greenlet]\n",
      "   ---------------- ----------------------- 16/39 [greenlet]\n",
      "   ---------------- ----------------------- 16/39 [greenlet]\n",
      "   ---------------- ----------------------- 16/39 [greenlet]\n",
      "   ---------------- ----------------------- 16/39 [greenlet]\n",
      "   ---------------- ----------------------- 16/39 [greenlet]\n",
      "   ----------------- ---------------------- 17/39 [frozenlist]\n",
      "   ------------------- -------------------- 19/39 [aiohappyeyeballs]\n",
      "   ------------------- -------------------- 19/39 [aiohappyeyeballs]\n",
      "   -------------------- ------------------- 20/39 [yarl]\n",
      "   -------------------- ------------------- 20/39 [yarl]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 22/39 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 23/39 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 23/39 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 23/39 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 23/39 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 23/39 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 23/39 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 23/39 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 23/39 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 23/39 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 23/39 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 23/39 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 23/39 [requests-toolbelt]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   ------------------------ --------------- 24/39 [pydantic]\n",
      "   -------------------------- ------------- 26/39 [pydantic-settings]\n",
      "   -------------------------- ------------- 26/39 [pydantic-settings]\n",
      "   -------------------------- ------------- 26/39 [pydantic-settings]\n",
      "   -------------------------- ------------- 26/39 [pydantic-settings]\n",
      "   -------------------------- ------------- 26/39 [pydantic-settings]\n",
      "   -------------------------- ------------- 26/39 [pydantic-settings]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   --------------------------- ------------ 27/39 [langsmith]\n",
      "   ---------------------------- ----------- 28/39 [langgraph-sdk]\n",
      "   ---------------------------- ----------- 28/39 [langgraph-sdk]\n",
      "   ---------------------------- ----------- 28/39 [langgraph-sdk]\n",
      "   ---------------------------- ----------- 28/39 [langgraph-sdk]\n",
      "   ----------------------------- ---------- 29/39 [dataclasses-json]\n",
      "   ----------------------------- ---------- 29/39 [dataclasses-json]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------ --------- 30/39 [aiohttp]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   ------------------------------- -------- 31/39 [langchain-core]\n",
      "   -------------------------------- ------- 32/39 [langgraph-checkpoint]\n",
      "   -------------------------------- ------- 32/39 [langgraph-checkpoint]\n",
      "   -------------------------------- ------- 32/39 [langgraph-checkpoint]\n",
      "   -------------------------------- ------- 32/39 [langgraph-checkpoint]\n",
      "   -------------------------------- ------- 32/39 [langgraph-checkpoint]\n",
      "   -------------------------------- ------- 32/39 [langgraph-checkpoint]\n",
      "   -------------------------------- ------- 32/39 [langgraph-checkpoint]\n",
      "   -------------------------------- ------- 32/39 [langgraph-checkpoint]\n",
      "   -------------------------------- ------- 32/39 [langgraph-checkpoint]\n",
      "   --------------------------------- ------ 33/39 [langchain-text-splitters]\n",
      "   --------------------------------- ------ 33/39 [langchain-text-splitters]\n",
      "   --------------------------------- ------ 33/39 [langchain-text-splitters]\n",
      "   --------------------------------- ------ 33/39 [langchain-text-splitters]\n",
      "   ---------------------------------- ----- 34/39 [langgraph-prebuilt]\n",
      "   ---------------------------------- ----- 34/39 [langgraph-prebuilt]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ----------------------------------- ---- 35/39 [langchain-classic]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------ --- 36/39 [langgraph]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   ------------------------------------- -- 37/39 [langchain-community]\n",
      "   -------------------------------------- - 38/39 [langchain]\n",
      "   -------------------------------------- - 38/39 [langchain]\n",
      "   -------------------------------------- - 38/39 [langchain]\n",
      "   -------------------------------------- - 38/39 [langchain]\n",
      "   -------------------------------------- - 38/39 [langchain]\n",
      "   -------------------------------------- - 38/39 [langchain]\n",
      "   -------------------------------------- - 38/39 [langchain]\n",
      "   -------------------------------------- - 38/39 [langchain]\n",
      "   -------------------------------------- - 38/39 [langchain]\n",
      "   ---------------------------------------- 39/39 [langchain]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.45 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 annotated-types-0.7.0 dataclasses-json-0.6.7 frozenlist-1.8.0 greenlet-3.3.0 httpx-sse-0.4.3 jsonpatch-1.33 langchain-1.2.1 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-core-1.2.6 langchain-text-splitters-1.1.0 langgraph-1.0.5 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.3.1 langsmith-0.6.1 marshmallow-3.26.2 multidict-6.7.0 mypy-extensions-1.1.0 numpy-2.4.0 orjson-3.11.5 ormsgpack-1.12.1 propcache-0.4.1 pydantic-2.12.5 pydantic-core-2.41.5 pydantic-settings-2.12.0 python-dotenv-1.2.1 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspect-0.9.0 typing-inspection-0.4.2 uuid-utils-0.12.0 xxhash-3.6.0 yarl-1.22.0 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-core langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4933f02a-6cdf-4778-9162-9728a8deecb8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-6.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.7-cp310-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pypdf-6.5.0-py3-none-any.whl (329 kB)\n",
      "Downloading pymupdf-1.26.7-cp310-abi3-win_amd64.whl (18.4 MB)\n",
      "   ---------------------------------------- 0.0/18.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/18.4 MB 4.0 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.3/18.4 MB 3.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.1/18.4 MB 3.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.9/18.4 MB 3.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 3.7/18.4 MB 3.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 4.5/18.4 MB 3.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 5.2/18.4 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 6.0/18.4 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 6.8/18.4 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 7.6/18.4 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 8.7/18.4 MB 3.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 9.4/18.4 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 10.2/18.4 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 11.0/18.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 11.8/18.4 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 12.6/18.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 13.4/18.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 14.2/18.4 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 15.2/18.4 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 16.0/18.4 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 16.8/18.4 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.6/18.4 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.4/18.4 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.4/18.4 MB 3.8 MB/s  0:00:04\n",
      "Installing collected packages: pypdf, pymupdf\n",
      "\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   ---------------------------------------- 0/2 [pypdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   ---------------------------------------- 2/2 [pymupdf]\n",
      "\n",
      "Successfully installed pymupdf-1.26.7 pypdf-6.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfc335d-7cc8-41e4-ab75-e683b134b3a4",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc69b395-7ff7-4aa9-b0a4-1243bd45a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Document structure\n",
    "\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2615bdb6-0690-48ac-8ce8-ba82c87818a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example.txt', 'pages': 1, 'author': 'Diptiranjan Nayak', 'date_created': '2025-01-01'}, page_content='this is the main text context I am using to create RAG')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = Document(\n",
    "    page_content=\"this is the main text context I am using to create RAG\",\n",
    "    metadata = {\n",
    "        \"source\": \"example.txt\",\n",
    "        \"pages\":1,\n",
    "        \"author\": \"Diptiranjan Nayak\",\n",
    "        \"date_created\":\"2025-01-01\"\n",
    "    }\n",
    ")\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386640e4-a073-4738-bdbe-72e2fd9dbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a simple txt file\n",
    "\n",
    "import os\n",
    "os.makedirs(\"data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d239dba1-0228-42ff-a7d6-4fe45569118f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "sample_texts={\n",
    "    \"data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\" Sample text files created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "291d524b-522e-44b9-8339-5df72f9770f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "## TextLoader - to read the file using it\n",
    "\n",
    "# from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/text_files/python_intro.txt\", encoding = \"utf-8\")\n",
    "document=loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74da28f5-aeac-4b2e-8d5b-d091e3cac195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '),\n",
       " Document(metadata={'source': 'data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Directory Loader\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# to load all the text files from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"data/text_files\",\n",
    "    glob = \"**/*.txt\",  # Pattern to match the files\n",
    "    loader_cls = TextLoader,  # loader class to use\n",
    "    loader_kwargs = {'encoding':'utf-8'},\n",
    "    show_progress = False\n",
    ")\n",
    "\n",
    "documents = dir_loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3556d98a-93fa-4c22-905f-792a1f11196a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 0}, page_content='# Q1\\nimport pandas as pd\\n# Create dataset\\ndata = {\\n    \\'length\\': [20, 30, 25, 35, 40],\\n    \\'breadth\\': [15, 20, 18, 22, 25],\\n    \\'price\\': [2000000, 3500000, 2800000, 4200000, 5500000]\\n}\\ndf = pd.DataFrame(data)\\n# New feature: total floor area\\ndf[\\'floor_area\\'] = df[\\'length\\'] * df[\\'breadth\\']\\nprint(df)\\nprint(\"\\\\nCorrelation with price:\")\\nprint(df.corr()[\\'price\\'])\\n   length  breadth    price  floor_area\\n0      20       15  2000000         300\\n1      30       20  3500000         600\\n2      25       18  2800000         450\\n3      35       22  4200000         770\\n4      40       25  5500000        1000\\nCorrelation with price:\\nlength        0.991327\\nbreadth       0.994763\\nprice         1.000000\\nfloor_area    0.998616\\nName: price, dtype: float64\\n# Q2\\nimport pandas as pd\\ndata = {\\n    \\'gender\\': [\\'Male\\', \\'Female\\', \\'Female\\', \\'Male\\'],\\n    \\'city\\': [\\'Delhi\\', \\'Mumbai\\', \\'Delhi\\', \\'Chennai\\'],\\n    \\'qualification\\': [\\'Graduate\\', \\'Postgraduate\\', \\'Graduate\\', \\'PhD\\']\\n}\\ndf = pd.DataFrame(data)\\n# One-hot encoding\\ndf_encoded = pd.get_dummies(df)\\nprint(df_encoded)\\nIn\\xa0[4]:\\nIn\\xa0[3]:\\n12/19/25, 10:54 AM\\nFeature Engineering\\nlocalhost:8889/lab/tree/Documents/College-MLC/Feature Engineering.ipynb\\n1/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 1}, page_content=\"gender_Female  gender_Male  city_Chennai  city_Delhi  city_Mumbai  \\\\\\n0          False         True         False        True        False   \\n1           True        False         False       False         True   \\n2           True        False         False        True        False   \\n3          False         True          True       False        False   \\n   qualification_Graduate  qualification_PhD  qualification_Postgraduate  \\n0                    True              False                       False  \\n1                   False              False                        True  \\n2                    True              False                       False  \\n3                   False               True                       False  \\n# Q3\\nimport pandas as pd\\ndata = {\\n    'satisfaction': ['Excellent', 'Good', 'Average', 'Poor', 'Good']\\n}\\ndf = pd.DataFrame(data)\\nmapping = {\\n    'Poor': 1,\\n    'Average': 2,\\n    'Good': 3,\\n    'Excellent': 4\\n}\\ndf['satisfaction_encoded'] = df['satisfaction'].map(mapping)\\nprint(df)\\n  satisfaction  satisfaction_encoded\\n0    Excellent                     4\\n1         Good                     3\\n2      Average                     2\\n3         Poor                     1\\n4         Good                     3\\n# Q4\\nimport pandas as pd\\ndata = {\\n    'price': [500, 1500, 3000, 7000, 12000]\\n}\\ndf = pd.DataFrame(data)\\ndf['price_category'] = pd.cut(\\n    df['price'],\\n    bins=[0, 2000, 6000, 15000],\\n    labels=['Low', 'Medium', 'High']\\n)\\nprint(df)\\nIn\\xa0[5]:\\nIn\\xa0[6]:\\n12/19/25, 10:54 AM\\nFeature Engineering\\nlocalhost:8889/lab/tree/Documents/College-MLC/Feature Engineering.ipynb\\n2/5\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 2}, page_content='price price_category\\n0    500            Low\\n1   1500            Low\\n2   3000         Medium\\n3   7000           High\\n4  12000           High\\n# Q5\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom sklearn.decomposition import PCA\\n# Numeric dataset\\nX = np.random.rand(100, 5)\\npca = PCA(n_components=2)\\nX_pca = pca.fit_transform(X)\\nplt.figure()\\nplt.scatter(X_pca[:, 0], X_pca[:, 1])\\nplt.title(\"PCA - 2 Components\")\\nplt.xlabel(\"PC1\")\\nplt.ylabel(\"PC2\")\\nplt.grid(True, linestyle=\\'--\\', alpha=0.5)\\nplt.show()\\n# Q6\\nimport numpy as np\\n# Generate numeric dataset\\nIn\\xa0[3]:\\nIn\\xa0[8]:\\n12/19/25, 10:54 AM\\nFeature Engineering\\nlocalhost:8889/lab/tree/Documents/College-MLC/Feature Engineering.ipynb\\n3/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 3}, page_content='X = np.random.rand(5, 4)\\n# SVD\\nU, S, Vt = np.linalg.svd(X, full_matrices=False)\\n# Reconstruct matrix\\nX_approx = U @ np.diag(S) @ Vt\\nprint(\"Original Matrix:\\\\n\", X)\\nprint(\"\\\\nReconstructed Matrix:\\\\n\", X_approx)\\nOriginal Matrix:\\n [[0.65438659 0.76322352 0.63328156 0.13640117]\\n [0.55989237 0.99178825 0.59773302 0.14767012]\\n [0.40366844 0.54514935 0.24724823 0.24567122]\\n [0.19468232 0.86078516 0.88215269 0.73651777]\\n [0.77669607 0.491355   0.7887976  0.93835776]]\\nReconstructed Matrix:\\n [[0.65438659 0.76322352 0.63328156 0.13640117]\\n [0.55989237 0.99178825 0.59773302 0.14767012]\\n [0.40366844 0.54514935 0.24724823 0.24567122]\\n [0.19468232 0.86078516 0.88215269 0.73651777]\\n [0.77669607 0.491355   0.7887976  0.93835776]]\\n# Q7\\nfrom sklearn.datasets import load_iris\\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\\n# Load labeled dataset\\ndata = load_iris()\\nX = data.data\\ny = data.target\\nlda = LinearDiscriminantAnalysis(n_components=2)\\nX_lda = lda.fit_transform(X, y)\\nprint(\"LDA transformed shape:\", X_lda.shape)\\nLDA transformed shape: (150, 2)\\n# Q8\\nfrom sklearn.datasets import load_iris\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score\\ndata = load_iris()\\nX = data.data\\ny = data.target\\n# Full dataset\\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\\nmodel_full = LogisticRegression(max_iter=200)\\nmodel_full.fit(X_train, y_train)\\nacc_full = accuracy_score(y_test, model_full.predict(X_test))\\n# Subset of columns\\nX_subset = X[:, :2]\\nIn\\xa0[9]:\\nIn\\xa0[10]:\\n12/19/25, 10:54 AM\\nFeature Engineering\\nlocalhost:8889/lab/tree/Documents/College-MLC/Feature Engineering.ipynb\\n4/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 4}, page_content='X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_subset, y, random_\\nmodel_subset = LogisticRegression(max_iter=200)\\nmodel_subset.fit(X_train_s, y_train_s)\\nacc_subset = accuracy_score(y_test_s, model_subset.predict(X_test_s))\\nprint(\"Accuracy (Full features):\", acc_full)\\nprint(\"Accuracy (Subset features):\", acc_subset)\\nAccuracy (Full features): 1.0\\nAccuracy (Subset features): 0.8421052631578947\\n# Q9\\nimport pandas as pd\\nimport numpy as np\\n# Create correlated dataset\\nnp.random.seed(0)\\nx1 = np.random.rand(100)\\nx2 = x1 * 0.9 + np.random.rand(100) * 0.1\\nx3 = np.random.rand(100)\\ndf = pd.DataFrame({\\n    \\'feature1\\': x1,\\n    \\'feature2\\': x2,\\n    \\'feature3\\': x3\\n})\\n# Correlation matrix\\ncorr = df.corr()\\nprint(\"Correlation Matrix:\\\\n\", corr)\\n# Drop highly correlated feature\\ndf_reduced = df.drop(\\'feature2\\', axis=1)\\nprint(\"\\\\nReduced Dataset:\\\\n\", df_reduced.head())\\nCorrelation Matrix:\\n           feature1  feature2  feature3\\nfeature1  1.000000  0.994307 -0.036512\\nfeature2  0.994307  1.000000 -0.049809\\nfeature3 -0.036512 -0.049809  1.000000\\nReduced Dataset:\\n    feature1  feature3\\n0  0.548814  0.311796\\n1  0.715189  0.696343\\n2  0.602763  0.377752\\n3  0.544883  0.179604\\n4  0.423655  0.024679\\n \\nIn\\xa0[11]:\\nIn\\xa0[\\xa0]:\\n12/19/25, 10:54 AM\\nFeature Engineering\\nlocalhost:8889/lab/tree/Documents/College-MLC/Feature Engineering.ipynb\\n5/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'file_path': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'INFLUCRAFT PRIVATE LIMITED-One Page Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='INFLUCRAFT PRIVATE LIMITED \\nDomain : Creator Economy | Creator Tech | AI + SAAS \\nCompany Overview \\nInflucraft is a Creator-Tech platform that helps creators run their work like a real business. \\nToday, creator campaigns are managed through WhatsApp, emails, and PDFs. This leads to \\nmessy workflows, delayed approvals, payment confusion, and zero automation. Creators \\ndont have proper systems to manage campaigns, teams, content, and money in one place. \\nInflucraft fixes this by giving creators a single intelligent platform to manage campaigns, \\ncontent, teams, and payments using AI-driven automation.\\u200b\\nInflucraft is not a creator marketplace or discovery platform. \\nWhat Does Influcraft Do? \\nInflucraft provides creators and brands a structured system to: \\n\\u200b Execute campaigns end-to-end \\n\\u200b Track deliverables and approvals \\n\\u200b Automate workflows using AI \\n\\u200b Manage teams and content \\n\\u200b Handle payments transparently \\nIt replaces chaos with systems. \\n \\nPlatform & Core Features \\n1.  AI Workflow Automation (Core Engine) \\nCreators or brands can start a campaign by: \\n\\u200b Uploading the campaign brief (PDF, email, text), or \\n\\u200b Using a drag-and-drop workflow builder. \\nInflucrafts AI then: \\n\\u200b Extracts deliverables \\n\\u200b Builds structured workflows'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'file_path': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'INFLUCRAFT PRIVATE LIMITED-One Page Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1}, page_content='\\u200b Tracks deliverables from both creator and brand side \\n\\u200b Assigns tasks (integrated with Creator Studio if used) \\n\\u200b Sets timelines and milestones \\n\\u200b Tracks progress in real time \\nAfter both sides agree on terms: \\n\\u200b The brand deposits the full campaign amount into Influcrafts escrow \\n\\u200b Payments are linked to deliverables \\n\\u200b As deliverables are verified, the system auto-releases payments to the creator \\nThis creates a trust loop:\\u200b\\n Deliverables  Verification  Auto Payment  Trust \\n  \\n2.  Creator CMS \\nCreators manage their entire digital presence from one dashboard: \\n\\u200b Blogs \\n\\u200b Newsletters \\n\\u200b Content calendar \\n\\u200b Content scheduling \\n\\u200b Personalized and domain-mapped websites \\n\\u200b Link-in-bio \\n\\u200b URL shortener \\n3.  Creator Studio \\nFor creators who run teams: \\n\\u200b Editors, designers, writers, managers \\n\\u200b Task assignment and tracking \\n\\u200b File sharing \\n\\u200b Team collaboration \\n\\u200b Deep integration with AI Workflow Automation \\n  \\n \\n4.  Financial Wallet & Ledger \\n\\u200b Escrow-based campaign payments \\n\\u200b Transparent income tracking \\n\\u200b Automated payouts \\n\\u200b Business-grade financial system for creators'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'file_path': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'INFLUCRAFT PRIVATE LIMITED-One Page Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2}, page_content='5.  Unified Creator ID & SSO \\n\\u200b One login for all Influcraft tools \\n\\u200b Easy future product expansion \\n\\u200b Unified identity across workflows \\nVision \\nTo elevate creators into businesses by giving them the same systems, automation, and \\nfinancial clarity that companies have. \\nLong-term, Influcraft aims to become the infrastructure layer of the creator economy. \\nProblem We Are Solving \\nCreators face: \\n\\u200b Scattered tools \\n\\u200b Manual coordination \\n\\u200b No financial clarity \\n\\u200b No business-grade systems \\nBrands face: \\n\\u200b No visibility into real workflows \\n\\u200b Delayed approvals \\n\\u200b Poor tracking of deliverables \\nThere is no unified Creator-Tech platform in India that manages campaigns, content, teams, \\nanalytics, and payments together. \\n \\n \\nOur Solution \\nInflucraft offers: \\n\\u200b AI-first workflow automation \\n\\u200b Business-grade creator systems \\n\\u200b End-to-end campaign execution \\n\\u200b Financial trust layer \\n\\u200b Data-driven creator growth'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'file_path': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'INFLUCRAFT PRIVATE LIMITED-One Page Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3}, page_content='Why Influcraft? \\nThe creator economy runs on chaos.\\u200b\\n Influcraft is building systems. \\nSo creators stop being freelancers \\u200b\\n And start being businesses. \\n    \\n Subodh Kumar Pradhan ,Purusottam Mohanta \\n Founders, Influcraft'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'file_path': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'Influcraft  Executive Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='Influcraft  Executive Summary \\nDomain: Creator Economy | Creator-Tech | AI + SaaS \\nCompany Overview \\nInflucraft is a Creator-Tech platform that helps creators run their work like a real business. \\nToday, most creator campaigns are managed through WhatsApp, emails, and PDFs. This \\ncreates messy workflows, delayed approvals, payment confusion, and zero automation. \\nCreators do not have proper systems to manage campaigns, teams, content, and money in \\none place. Influcraft fixes this by giving creators a single intelligent platform to manage \\ncampaigns, content, teams, and payments using AI-driven automation. Influcraft is not a \\ncreator marketplace or discovery platform. \\nWhat Does Influcraft Do? \\nInflucraft provides creators and brands a structured system to execute campaigns \\nend-to-end. It helps track deliverables and approvals, automate workflows using AI, manage \\nteams and content, and handle payments transparently. In simple words, Influcraft replaces \\nchaos with systems. \\nPlatform & Core Features \\nThe core of Influcraft is its AI Workflow Automation engine. Creators or brands can start a \\ncampaign by uploading a campaign brief such as a PDF or by using a drag-and-drop \\nworkflow builder. Influcrafts AI reads the brief, extracts deliverables, builds a structured \\nworkflow, assigns tasks, sets timelines, and tracks progress from both the creator and brand \\nside. This system is directly integrated with Creator Studio if the creator is working with a \\nteam. Once both sides agree on the terms and deliverables, the brand deposits the full \\ncampaign amount into Influcrafts escrow system. Payments are linked to deliverables, and \\nas soon as the deliverables and conditions are met, the system automatically releases the \\npayment to the creator. \\nInflucraft also provides a Creator CMS where creators manage their entire digital presence \\nfrom one dashboard. They can run blogs, newsletters, content scheduling, and content \\ncalendars, along with personalized and domain-mapped websites, link-in-bio pages, and \\nURL shorteners. This allows creators to operate like a real media business instead of using \\nmultiple disconnected tools. \\nFor creators who manage teams, Influcraft offers Creator Studio. It is a space where editors, \\ndesigners, writers, and managers can collaborate. It supports task assignment, file sharing, \\nteam communication, and is deeply integrated with the AI Workflow Automation system so \\nthat campaign work and team work stay in sync.It supports escrow-based campaign'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'file_path': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'Influcraft  Executive Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1}, page_content='payments, transparent income tracking, automated payouts, and a business-grade financial \\nstructure for creators.  \\nAlong with this, Influcraft provides a Unified Creator ID and Single Sign-On so creators use \\none login across all tools, making future expansion of features simple and seamless. \\nVision \\nInflucrafts vision is to elevate creators into businesses by giving them the same systems, \\nautomation, and financial clarity that companies have. In the long term, Influcraft aims to \\nbecome the infrastructure layer of the creator economy. \\nProblem We Are Solving \\nCreators today face scattered tools, manual coordination, no financial clarity, and no \\nbusiness-grade systems. Brands face poor visibility into real workflows, delayed approvals, \\nand weak tracking of deliverables. There is no unified Creator-Tech platform in India that \\nmanages campaigns, content, teams, analytics, and payments together in one system. \\nOur Solution \\nInflucraft solves this by offering AI-first workflow automation, business-grade creator \\nsystems, end-to-end campaign execution, a financial trust layer, and data-driven tools for \\ncreator growth  all inside one unified platform. \\nWhy Influcraft? \\nThe creator economy today runs on chaos. Influcraft is building systems. So creators stop \\nbeing freelancers  and start being businesses. \\n \\n \\n \\n \\n \\n \\n \\nSubodh Kumar Pradhan \\nFounder \\nPurusottam Mohanta \\nCo-Founder'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:21:50+00:00', 'source': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Matplotlib.i (2) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:21:50+00:00', 'trapped': '', 'modDate': \"D:20251219052150+00'00'\", 'creationDate': \"D:20251219052150+00'00'\", 'page': 0}, page_content='# Q1\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n# Student data\\ndata = {\\n    \\'Name\\': [\\'Rishika Batra\\', \\'Waseem Ali\\', \\'Kulpreet Singh\\', \\'Annie Mathews\\', \\'\\n             \\'Naveen Gupta\\', \\'Taleem Ahmed\\', \\'Pragati Nigam\\', \\'Usman Abbas\\'],\\n    \\'English\\': [95, 95, 78, 88, 95, 82, 73, 80, 92],\\n    \\'Maths\\': [95, 76, 81, 63, 55, 55, 49, 50, 43],\\n    \\'Hindi\\': [90, 79, 75, 67, 51, 63, 54, 51, 51],\\n    \\'Science\\': [94, 77, 76, 77, 59, 56, 60, 54, 48],\\n    \\'Social Studies\\': [95, 89, 88, 80, 80, 74, 77, 76, 69]\\n}\\ndf = pd.DataFrame(data)\\n# Boxplot\\ndf.drop(\\'Name\\', axis=1).plot(kind=\\'box\\', figsize=(10,6), title=\\'Student Performa\\nplt.ylabel(\"Marks\")\\nplt.grid(True, linestyle=\\'--\\', alpha=0.8)\\nplt.show()\\n# Q2\\nimport matplotlib.pyplot as plt\\ndiscounts = [10, 20, 30, 40, 50]\\nsales = [40000, 45000, 48000, 50000, 100000]\\nplt.scatter(discounts, sales, color=\\'green\\', marker=\\'o\\')\\nplt.title(\"Discount vs Sales for Designer Bags and Wallets\")\\nplt.xlabel(\"Discount (%)\")\\nplt.ylabel(\"Sales (Rs.)\")\\nIn\\xa0[22]:\\nIn\\xa0[14]:\\n12/19/25, 10:51 AM\\nMatplotlib\\nlocalhost:8889/lab/tree/Documents/College-MLC/Matplotlib.ipynb\\n1/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:21:50+00:00', 'source': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Matplotlib.i (2) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:21:50+00:00', 'trapped': '', 'modDate': \"D:20251219052150+00'00'\", 'creationDate': \"D:20251219052150+00'00'\", 'page': 1}, page_content='plt.grid(True, linestyle=\\'--\\', alpha=0.4)\\nplt.show()\\n# Q3 - (a)\\nimport pandas as pd\\nurl = \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mp\\ncolumns = [\\'mpg\\',\\'cylinders\\',\\'displacement\\',\\'horsepower\\',\\'weight\\',\\n           \\'acceleration\\',\\'model_year\\',\\'origin\\',\\'car_name\\']\\ndf = pd.read_csv(url, sep=\\'\\\\s+\\', names=columns, na_values=\\'?\\')\\nprint(\"Original shape:\", df.shape)\\ndf = df.dropna()\\ndf[\\'horsepower\\'] = pd.to_numeric(df[\\'horsepower\\'])\\nprint(\"Cleaned shape:\", df.shape)\\nprint(df.head())\\nIn\\xa0[6]:\\n12/19/25, 10:51 AM\\nMatplotlib\\nlocalhost:8889/lab/tree/Documents/College-MLC/Matplotlib.ipynb\\n2/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:21:50+00:00', 'source': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Matplotlib.i (2) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:21:50+00:00', 'trapped': '', 'modDate': \"D:20251219052150+00'00'\", 'creationDate': \"D:20251219052150+00'00'\", 'page': 2}, page_content='Original shape: (398, 9)\\nCleaned shape: (392, 9)\\n    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\\\\n0  18.0          8         307.0       130.0  3504.0          12.0   \\n1  15.0          8         350.0       165.0  3693.0          11.5   \\n2  18.0          8         318.0       150.0  3436.0          11.0   \\n3  16.0          8         304.0       150.0  3433.0          12.0   \\n4  17.0          8         302.0       140.0  3449.0          10.5   \\n   model_year  origin                   car_name  \\n0          70       1  chevrolet chevelle malibu  \\n1          70       1          buick skylark 320  \\n2          70       1         plymouth satellite  \\n3          70       1              amc rebel sst  \\n4          70       1                ford torino  \\n# Q3 - b\\nimport matplotlib.pyplot as plt\\nplt.figure(figsize=(8,6))\\nplt.scatter(df[\\'horsepower\\'], df[\\'mpg\\'], alpha=0.7, color=\\'blue\\')\\nplt.xlabel(\"Horsepower\")\\nplt.ylabel(\"Miles per Gallon (MPG)\")\\nplt.title(\"Horsepower vs MPG\")\\nplt.grid(True, linestyle=\\'--\\', alpha=0.6)\\nplt.show()\\n# Q3 - c\\nplt.figure(figsize=(8,6))\\nplt.hist(df[\\'mpg\\'], bins=18, color=\\'skyblue\\', edgecolor=\\'black\\')\\nIn\\xa0[7]:\\nIn\\xa0[15]:\\n12/19/25, 10:51 AM\\nMatplotlib\\nlocalhost:8889/lab/tree/Documents/College-MLC/Matplotlib.ipynb\\n3/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:21:50+00:00', 'source': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Matplotlib.i (2) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:21:50+00:00', 'trapped': '', 'modDate': \"D:20251219052150+00'00'\", 'creationDate': \"D:20251219052150+00'00'\", 'page': 3}, page_content='plt.xlabel(\"Miles per Gallon (MPG)\")\\nplt.ylabel(\"Frequency\")\\nplt.title(\"Distribution of MPG\")\\nplt.grid(True, linestyle=\\'--\\', alpha=0.8)\\nplt.show()\\n# Q3 - d\\nplt.figure(figsize=(8,6))\\ndf.boxplot(column=\\'mpg\\', by=\\'cylinders\\')\\nplt.xlabel(\"Number of Cylinders\")\\nplt.ylabel(\"Miles per Gallon (MPG)\")\\nplt.title(\"MPG Distribution by Cylinders\")\\nplt.suptitle(\"\")  # remove automatic title\\nplt.grid(True, linestyle=\\'--\\', alpha=0.5)\\nplt.show()\\n<Figure size 800x600 with 0 Axes>\\nIn\\xa0[18]:\\n12/19/25, 10:51 AM\\nMatplotlib\\nlocalhost:8889/lab/tree/Documents/College-MLC/Matplotlib.ipynb\\n4/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:21:50+00:00', 'source': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Matplotlib.i (2) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:21:50+00:00', 'trapped': '', 'modDate': \"D:20251219052150+00'00'\", 'creationDate': \"D:20251219052150+00'00'\", 'page': 4}, page_content='In\\xa0[\\xa0]:\\n12/19/25, 10:51 AM\\nMatplotlib\\nlocalhost:8889/lab/tree/Documents/College-MLC/Matplotlib.ipynb\\n5/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 0}, page_content='# Q1\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\ndata = pd.read_csv(\\'auto_mpg.csv\\')\\nprint(data.shape)\\ntrain_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\\nprint(\"\\\\nTraining set:\")\\nprint(train_df)\\nprint(\"Training set length:\", len(train_df))\\nprint(\"\\\\nTest set:\")\\nprint(test_df)\\nprint(\"Test set length:\", len(test_df))\\nIn\\xa0[3]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n1/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 1}, page_content='(398, 9)\\nTraining set:\\n      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\\\\n3    16.0          8         304.0       150.0  3433.0          12.0   \\n18   27.0          4          97.0        88.0  2130.0          14.5   \\n376  37.0          4          91.0        68.0  2025.0          18.2   \\n248  36.1          4          91.0        60.0  1800.0          16.4   \\n177  23.0          4         115.0        95.0  2694.0          15.0   \\n..    ...        ...           ...         ...     ...           ...   \\n71   19.0          3          70.0        97.0  2330.0          13.5   \\n106  12.0          8         350.0       180.0  4499.0          12.5   \\n270  21.1          4         134.0        95.0  2515.0          14.8   \\n348  37.7          4          89.0        62.0  2050.0          17.3   \\n102  26.0          4          97.0        46.0  1950.0          21.0   \\n     model_year  origin                   car_name  \\n3            70       1              amc rebel sst  \\n18           70       3               datsun pl510  \\n376          82       3         mazda glc custom l  \\n248          78       3           honda civic cvcc  \\n177          75       2                 audi 100ls  \\n..          ...     ...                        ...  \\n71           72       3            mazda rx2 coupe  \\n106          73       1   oldsmobile vista cruiser  \\n270          78       3  toyota celica gt liftback  \\n348          81       3              toyota tercel  \\n102          73       2    volkswagen super beetle  \\n[318 rows x 9 columns]\\nTraining set length: 318\\nTest set:\\n      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\\\\n198  33.0          4          91.0        53.0  1795.0          17.4   \\n396  28.0          4         120.0        79.0  2625.0          18.6   \\n33   19.0          6         232.0       100.0  2634.0          13.0   \\n208  13.0          8         318.0       150.0  3940.0          13.2   \\n93   14.0          8         318.0       150.0  4237.0          14.5   \\n..    ...        ...           ...         ...     ...           ...   \\n249  19.9          8         260.0       110.0  3365.0          15.5   \\n225  17.5          6         250.0       110.0  3520.0          16.4   \\n367  28.0          4         112.0        88.0  2605.0          19.6   \\n175  29.0          4          90.0        70.0  1937.0          14.0   \\n285  17.0          8         305.0       130.0  3840.0          15.4   \\n     model_year  origin                           car_name  \\n198          76       3                        honda civic  \\n396          82       1                        ford ranger  \\n33           71       1                        amc gremlin  \\n208          76       1         plymouth volare premier v8  \\n93           73       1           plymouth fury gran sedan  \\n..          ...     ...                                ...  \\n249          78       1  oldsmobile cutlass salon brougham  \\n225          77       1                 chevrolet concours  \\n367          82       1                 chevrolet cavalier  \\n175          75       2                  volkswagen rabbit  \\n285          79       1          chevrolet caprice classic  \\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n2/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 2}, page_content='[80 rows x 9 columns]\\nTest set length: 80\\n# Q2\\nfrom sklearn.model_selection import KFold\\n# Load dataset\\ndf = pd.read_csv(\"btissue.csv\")\\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\\nfor fold, (train_index, test_index) in enumerate(kf.split(df)):\\n    print(f\"\\\\nFold {fold}\")\\n    print(\"Training indices:\", train_index)\\n    print(\"Test indices:\", test_index)\\n    # 3rd iteration (fold index = 2)\\n    if fold == 2:\\n        train_set = df.iloc[train_index]\\n        test_set = df.iloc[test_index]\\n        print(\"\\\\nTraining set (3rd fold):\")\\n        print(train_set)\\n        print(\"Training set length:\", len(train_set))\\n        print(\"\\\\nTest set (3rd fold):\")\\n        print(test_set)\\n        print(\"Test set length:\", len(test_set))\\nIn\\xa0[10]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n3/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 3}, page_content='Fold 0\\nTraining indices: [  1   2   3   5   6   7   8   9  13  14  15  16  17  19  20  2\\n1  22  23\\n  24  25  26  27  28  29  31  32  34  35  36  37  38  39  40  41  43  45\\n  46  48  49  50  51  52  53  54  56  57  58  59  60  61  62  63  66  68\\n  69  70  71  72  73  74  75  76  77  82  83  84  85  86  87  88  89  90\\n  91  92  94  95  96  98  99 101 102 103 104 105]\\nTest indices: [  0   4  10  11  12  18  30  33  42  44  47  55  64  65  67  78  7\\n9  80\\n  81  93  97 100]\\nFold 1\\nTraining indices: [  0   1   2   3   4   6   7   8  10  11  12  13  14  17  18  1\\n9  20  21\\n  23  24  25  27  29  30  32  33  34  37  38  41  42  43  44  46  47  48\\n  49  50  51  52  54  55  56  57  58  59  60  61  63  64  65  66  67  68\\n  69  70  71  72  74  75  78  79  80  81  82  83  84  85  86  87  89  90\\n  91  92  93  94  96  97  98  99 100 101 102 103 105]\\nTest indices: [  5   9  15  16  22  26  28  31  35  36  39  40  45  53  62  73  7\\n6  77\\n  88  95 104]\\nFold 2\\nTraining indices: [  0   1   2   4   5   9  10  11  12  14  15  16  18  20  21  2\\n2  23  26\\n  28  29  30  31  32  33  35  36  37  39  40  41  42  44  45  46  47  48\\n  50  51  52  53  54  55  57  58  59  60  61  62  63  64  65  67  68  71\\n  72  73  74  75  76  77  78  79  80  81  82  83  84  86  87  88  89  91\\n  92  93  94  95  96  97  99 100 101 102 103 104 105]\\nTest indices: [ 3  6  7  8 13 17 19 24 25 27 34 38 43 49 56 66 69 70 85 90 98]\\nTraining set (3rd fold):\\n              I0     PA500       HFS           DA           Area        A/DA  \\\\\\n0     524.794072  0.187448  0.032114   228.800228    6843.598481   29.910803   \\n1     330.000000  0.226893  0.265290   121.154201    3163.239472   26.109202   \\n2     551.879287  0.232478  0.063530   264.804935   11888.391830   44.894903   \\n4     362.831266  0.200713  0.244346   124.912559    3290.462446   26.342127   \\n5     389.872978  0.150098  0.097738   118.625814    2475.557078   20.868620   \\n..           ...       ...       ...          ...            ...         ...   \\n101  2000.000000  0.106989  0.105418   520.222649   40087.920980   77.059161   \\n102  2600.000000  0.200538  0.208043  1063.441427  174480.476200  164.071543   \\n103  1600.000000  0.071908 -0.066323   436.943603   12655.342130   28.963331   \\n104  2300.000000  0.045029  0.136834   185.446044    5086.292497   27.427344   \\n105  2600.000000  0.069988  0.048869   745.474369   39845.773700   53.450226   \\n         Max IP          DR            P class  \\n0     60.204880  220.737212   556.828334   car  \\n1     69.717361   99.084964   400.225776   car  \\n2     77.793297  253.785300   656.769449   car  \\n4     69.389389  103.866552   424.796503   car  \\n5     49.757149  107.686164   429.385788   car  \\n..          ...         ...          ...   ...  \\n101  204.090347  478.517223  2088.648870   adi  \\n102  418.687286  977.552367  2664.583623   adi  \\n103  103.732704  432.129749  1475.371534   adi  \\n104  178.691742   49.593290  2480.592151   adi  \\n105  154.122604  729.368395  2545.419744   adi  \\n[85 rows x 10 columns]\\nTraining set length: 85\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n4/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 4}, page_content='Test set (3rd fold):\\n             I0     PA500       HFS          DA          Area       A/DA  \\\\\\n3    380.000000  0.240855  0.286234  137.640111   5402.171180  39.248524   \\n6    290.455141  0.144164  0.053058   74.635067   1189.545213  15.938154   \\n7    275.677393  0.153938  0.187797   91.527893   1756.234837  19.187974   \\n8    470.000000  0.213105  0.225497  184.590057   8185.360837  44.343455   \\n13   366.942379  0.280125  0.252026  172.745554   7064.815909  40.897237   \\n17   300.000000  0.190066  0.166853   97.108130   3039.561303  31.300791   \\n19   294.474846  0.206647  0.467748  194.871035   5541.256126  28.435504   \\n24   352.656447  0.121999  0.090757   68.527846   1066.157846  15.558024   \\n25   243.293976  0.039968  0.067021   68.544778    383.928453   5.601134   \\n27   250.000000  0.068068 -0.015359   57.172431    652.901349  11.419863   \\n34   155.000000  0.172788  0.118682   38.940168    415.111601  10.660242   \\n38   435.093167  0.076969  0.161268  123.597538   1342.277648  10.860068   \\n43   252.000000  0.106116  0.031416   38.544210    493.790423  12.811014   \\n49   544.654349  0.063705  0.002094  100.788080   1189.290233  11.799910   \\n56   152.000000  0.165806  0.227591   34.219550     94.354328   2.757322   \\n66   176.000000  0.089884  0.076794   20.588524     79.705425   3.871352   \\n69   103.000000  0.158127  0.291819   23.754811     78.258474   3.294426   \\n70  1724.089894  0.052709 -0.020944  404.126208   3053.966890   7.556963   \\n85  1800.000000  0.034208  0.042586  301.060351   4406.154331  14.635452   \\n90  1850.000000  0.079149  0.069470  253.621455  13113.203090  51.703840   \\n98  2329.840138  0.066148  0.353255  377.253368  25369.039920  67.246689   \\n        Max IP          DR            P class  \\n3    88.758446  105.198568   493.701814   car  \\n6    35.703331   65.541324   330.267293   car  \\n7    39.305183   82.658682   331.588302   car  \\n8    84.482483  164.122511   603.315715   car  \\n13   75.604324  155.322285   471.588195   car  \\n17   51.353973   82.418192   387.078228   car  \\n19   36.765797  191.804890   445.513299   car  \\n24   43.691925   52.792817   382.733186   fad  \\n25    9.991348   67.816656   263.640761   fad  \\n27   17.776981   55.791270   278.308615   fad  \\n34   25.836502   29.134376   184.817041   fad  \\n38   37.384724  117.808038   433.202322   mas  \\n43   25.541145   28.867040   280.658299   mas  \\n49   29.412222   96.580150   553.358210   mas  \\n56   31.279278   13.877478   180.609553   gla  \\n66   18.226492    9.575088   191.992878   gla  \\n69   22.323603    8.120826   124.978561   gla  \\n70   71.427589  399.194244  1489.386712   con  \\n85   67.625328  293.366920  1742.375702   adi  \\n90  160.065460  196.730498  1916.985365   adi  \\n98  336.075165  171.387227  2686.435346   adi  \\nTest set length: 21\\nFold 3\\nTraining indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  1\\n5  16  17\\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  33  34  35  36\\n  37  38  39  40  42  43  44  45  47  49  51  52  53  55  56  60  62  64\\n  65  66  67  69  70  71  73  74  76  77  78  79  80  81  82  85  86  87\\n  88  89  90  92  93  94  95  96  97  98 100 102 104]\\nTest indices: [ 32  41  46  48  50  54  57  58  59  61  63  68  72  75  83  84  9\\n1  99\\n 101 103 105]\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n5/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 5}, page_content='Fold 4\\nTraining indices: [  0   3   4   5   6   7   8   9  10  11  12  13  15  16  17  1\\n8  19  22\\n  24  25  26  27  28  30  31  32  33  34  35  36  38  39  40  41  42  43\\n  44  45  46  47  48  49  50  53  54  55  56  57  58  59  61  62  63  64\\n  65  66  67  68  69  70  72  73  75  76  77  78  79  80  81  83  84  85\\n  88  90  91  93  95  97  98  99 100 101 103 104 105]\\nTest indices: [  1   2  14  20  21  23  29  37  51  52  60  71  74  82  86  87  8\\n9  92\\n  94  96 102]\\n# Q3\\nfrom sklearn.utils import resample\\n# Load dataset\\ndf = pd.read_csv(\"btissue.csv\")\\n# 1. Extract predictors (assuming last column is target)\\nX = df.iloc[:, :-1]\\n# 2. Bootstrap sample of size 100\\nbootstrap_sample = resample(X, n_samples=100, random_state=42)\\n# 3. Display first 10 rows\\nprint(bootstrap_sample.head(10))\\n              I0     PA500       HFS           DA           Area        A/DA  \\\\\\n102  2600.000000  0.200538  0.208043  1063.441427  174480.476200  164.071543   \\n51    274.993396  0.147131  0.137532    66.457943    1217.415651   18.318588   \\n92   1800.000000  0.091979  0.205251   362.863321   15021.553890   41.397278   \\n14    485.668806  0.230209  0.134041   253.893699    8135.968359   32.044783   \\n71   1385.664721  0.092328  0.089361   202.480044    8785.028733   43.387134   \\n60    197.000000  0.132645  0.074002    33.460653     409.647141   12.242652   \\n20    500.000000  0.192684  0.194779   144.688578    3055.012963   21.114403   \\n102  2600.000000  0.200538  0.208043  1063.441427  174480.476200  164.071543   \\n82   1647.939811  0.080983  0.086568   576.770376   11852.485060   20.549747   \\n86   2100.000000  0.121649  0.377689   450.551667   35671.606290   79.173176   \\n         Max IP          DR            P  \\n102  418.687286  977.552367  2664.583623  \\n51    40.849678   52.421008   327.558639  \\n92   217.833969  290.203640  1893.663712  \\n14    64.855446  245.470531   541.363975  \\n71   143.092194  143.257780  1524.609204  \\n60    26.992807   19.773813   231.783788  \\n20    96.563370  107.751103   542.897089  \\n102  418.687286  977.552367  2664.583623  \\n82   111.435913  565.902910  1402.877737  \\n86   436.099640  113.198570  2461.450497  \\n# Q4\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score, confusion_matrix\\n# Load dataset\\ndf = pd.read_csv(\"btissue.csv\")\\n# 1. Separate predictors and target\\nIn\\xa0[11]:\\nIn\\xa0[12]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n6/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 6}, page_content='X = df.iloc[:, :-1]\\ny = df.iloc[:, -1]\\n# 2. Holdout split\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=42\\n)\\n# 3. Train Random Forest\\nmodel = RandomForestClassifier(random_state=42)\\nmodel.fit(X_train, y_train)\\n# 4. Evaluation\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\nprint(\"Confusion Matrix:\\\\n\", confusion_matrix(y_test, y_pred))\\nAccuracy: 0.7727272727272727\\nConfusion Matrix:\\n [[3 0 0 0 0 0]\\n [0 6 0 0 0 0]\\n [0 0 4 0 0 0]\\n [0 0 0 0 0 2]\\n [0 0 0 0 2 2]\\n [0 0 0 0 1 2]]\\n# Q5\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.metrics import mean_squared_error, r2_score\\n# Load dataset\\ndf = pd.read_csv(\"auto_mpg.csv\")\\n# 1. Remove rows with missing values\\ndf = df.dropna()\\ndf = pd.get_dummies(df, drop_first=True)\\n# 3. Separate predictors and target\\nX = df.drop(\"mpg\", axis=1)\\ny = df[\"mpg\"]\\n# 4. Train-test split (80% train, 20% test)\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=42\\n)\\n# 5. Train Linear Regression model\\nmodel = LinearRegression()\\nmodel.fit(X_train, y_train)\\n# 6. Predict on test data\\ny_pred = model.predict(X_test)\\n# 7. Evaluate the model\\nIn\\xa0[17]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n7/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 7}, page_content='print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\\nprint(\"R2 Score:\", r2_score(y_test, y_pred))\\nMean Squared Error: 16.958285786091167\\nR2 Score: 0.6677489811118411\\n# Q6\\nimport pandas as pd\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.metrics import v_measure_score, silhouette_score\\nfrom sklearn.preprocessing import LabelEncoder\\n# Load dataset\\ndf = pd.read_csv(\"Dataset_spine.csv\")\\ndf = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\\n# 1. Separate predictors and class column\\nX = df.iloc[:, :-1]        # Exclude class_att from predictors\\ny = df.iloc[:, -1]         # Keep class_att ONLY for evaluation\\n# 2. Encode class labels (required for v-measure)\\nle = LabelEncoder()\\ny_encoded = le.fit_transform(y)\\n# 3. Apply K-Means clustering\\nkmeans = KMeans(n_clusters=3, random_state=123)\\ny_pred = kmeans.fit_predict(X)\\n# 4. Compute quality measures\\nprint(\"V-measure Score:\", v_measure_score(y_encoded, y_pred))\\nprint(\"Silhouette Score:\", silhouette_score(X, y_pred))\\nV-measure Score: 0.24233882112188337\\nSilhouette Score: 0.3776387213379063\\nC:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\site-packages\\\\sklearn\\\\cluster\\\\_kmeans.py:1419: UserW\\narning: KMeans is known to have a memory leak on Windows with MKL, when there are \\nless chunks than available threads. You can avoid it by setting the environment v\\nariable OMP_NUM_THREADS=2.\\n  warnings.warn(\\nimport pandas as pd\\ndf = pd.read_csv(\\'Dataset_spine.csv\\')\\ndf\\nIn\\xa0[23]:\\nIn\\xa0[21]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n8/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 8}, page_content='\\uedd9\\n\\uedda\\nCol1\\nCol2\\nCol3\\nCol4\\nCol5\\nCol6\\nCol7\\nCo\\n0\\n63.027817\\n22.552586\\n39.609117\\n40.475232\\n98.672917\\n-0.254400\\n0.744503\\n12.56\\n1\\n39.056951\\n10.060991\\n25.015378\\n28.995960\\n114.405425\\n4.564259\\n0.415186\\n12.88\\n2\\n68.832021\\n22.218482\\n50.092194\\n46.613539\\n105.985135\\n-3.530317\\n0.474889\\n26.83\\n3\\n69.297008\\n24.652878\\n44.311238\\n44.644130\\n101.868495\\n11.211523\\n0.369345\\n23.56\\n4\\n49.712859\\n9.652075\\n28.317406\\n40.060784\\n108.168725\\n7.918501\\n0.543360\\n35.49\\n...\\n...\\n...\\n...\\n...\\n...\\n...\\n...\\n305\\n47.903565\\n13.616688\\n36.000000\\n34.286877\\n117.449062\\n-4.245395\\n0.129744\\n7.84\\n306\\n53.936748\\n20.721496\\n29.220534\\n33.215251\\n114.365845\\n-0.421010\\n0.047913\\n19.19\\n307\\n61.446597\\n22.694968\\n46.170347\\n38.751628\\n125.670725\\n-2.707880\\n0.081070\\n16.20\\n308\\n45.252792\\n8.693157\\n41.583126\\n36.559635\\n118.545842\\n0.214750\\n0.159251\\n14.73\\n309\\n33.841641\\n5.073991\\n36.641233\\n28.767649\\n123.945244\\n-0.199249\\n0.674504\\n19.38\\n310 rows  14 columns\\n \\nOut[21]:\\nIn\\xa0[\\xa0]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n9/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 0}, page_content='# Q1\\nimport pandas as pd\\nl1 = [10, 20, 30, 40, 50]\\nidx = [\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\']\\ns = pd.Series(l1, idx)\\n# (a) First 3 elements\\nprint(s.head(3))\\n# (b) Element at index \\'c\\'\\nprint(s[\\'c\\'])\\na    10\\nb    20\\nc    30\\ndtype: int64\\n30\\n# Q2\\nimport numpy as np\\nimport pandas as pd\\narr = np.random.randint(1, 101, size=10)\\ns2 = pd.Series(arr)\\n# (a) Max, Min, Mean\\nprint(\"Max:\", s2.max())\\nprint(\"Min:\", s2.min())\\nprint(\"Mean:\", s2.mean())\\n# (b) Square each element\\ns2_squared = s2.apply(lambda x: x**2)\\nprint(s2_squared)\\nMax: 98\\nMin: 1\\nMean: 37.4\\n0    3969\\n1    9604\\n2      64\\n3       1\\n4    1681\\n5     576\\n6    3136\\n7     729\\n8     225\\n9    1681\\ndtype: int64\\n# Q3\\ndata = {\\'Math\\': 85, \\'Science\\': 90, \\'English\\': 88}\\ns = pd.Series(data)\\nprint(s[\\'Science\\'])\\n90\\nIn\\xa0[1]:\\nIn\\xa0[2]:\\nIn\\xa0[6]:\\n12/19/25, 10:31 AM\\nNumpy_&_Pandas\\nlocalhost:8889/lab/tree/Documents/College-MLC/Numpy_%26_Pandas.ipynb\\n1/6'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 1}, page_content=\"# Q4\\ns4 = pd.Series([5, np.nan, 8, np.nan, 12])\\n# (a) Check missing values\\nprint(s4.isna())\\n# (b) Forward fill\\nprint(s4.fillna(method='ffill'))\\n# (c) Drop missing values\\nprint(s4.dropna())\\n0    False\\n1     True\\n2    False\\n3     True\\n4    False\\ndtype: bool\\n0     5.0\\n1     5.0\\n2     8.0\\n3     8.0\\n4    12.0\\ndtype: float64\\n0     5.0\\n2     8.0\\n4    12.0\\ndtype: float64\\nC:\\\\Users\\\\drnay\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_10328\\\\2187642790.py:9: FutureWarning: \\nSeries.fillna with 'method' is deprecated and will raise in a future version. Use \\nobj.ffill() or obj.bfill() instead.\\n  print(s4.fillna(method='ffill'))\\n# Q5\\ndata = {\\n    'Name': ['Amit', 'Riya', 'John', 'Sara'],\\n    'Age': [25, 30, 22, 28],\\n    'Salary': [50000, 60000, 55000, 65000]\\n}\\ndf = pd.DataFrame(data)\\n# (a) Age > 25\\nprint(df[df['Age'] > 25])\\n# (b) Salary between 55,000 and 65,000\\nprint(df[(df['Salary'] >= 55000) & (df['Salary'] <= 65000)])\\n   Name  Age  Salary\\n1  Riya   30   60000\\n3  Sara   28   65000\\n   Name  Age  Salary\\n1  Riya   30   60000\\n2  John   22   55000\\n3  Sara   28   65000\\n# Q6\\ndata = {\\nIn\\xa0[7]:\\nIn\\xa0[9]:\\nIn\\xa0[10]:\\n12/19/25, 10:31 AM\\nNumpy_&_Pandas\\nlocalhost:8889/lab/tree/Documents/College-MLC/Numpy_%26_Pandas.ipynb\\n2/6\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 2}, page_content=\"'Department': ['HR','IT','HR','IT','Finance'],\\n    'Employee': ['A','B','C','D','E'],\\n    'Salary': [40000, 50000, 42000, 55000, 60000]\\n}\\ndf2 = pd.DataFrame(data)\\n# (a) Average salary per department\\nprint(df2.groupby('Department')['Salary'].mean())\\n# (b) Employee count per department\\nprint(df2.groupby('Department')['Employee'].count())\\n# (c) Sort by Salary (ascending)\\nprint(df2.sort_values(by='Salary'))\\n# (d) Sort by Department, then Salary (descending)\\nprint(df2.sort_values(by=['Department', 'Salary'], ascending=[True, False]))\\nDepartment\\nFinance    60000.0\\nHR         41000.0\\nIT         52500.0\\nName: Salary, dtype: float64\\nDepartment\\nFinance    1\\nHR         2\\nIT         2\\nName: Employee, dtype: int64\\n  Department Employee  Salary\\n0         HR        A   40000\\n2         HR        C   42000\\n1         IT        B   50000\\n3         IT        D   55000\\n4    Finance        E   60000\\n  Department Employee  Salary\\n4    Finance        E   60000\\n2         HR        C   42000\\n0         HR        A   40000\\n3         IT        D   55000\\n1         IT        B   50000\\n# Q7\\ndata = {\\n    'Name': ['Amit', 'Riya', 'Amit', 'John', 'Riya'],\\n    'Age': [25, 30, 25, 22, 30]\\n}\\ndf3 = pd.DataFrame(data)\\n# (a) Display duplicate rows\\nprint(df3[df3.duplicated()])\\n# (b) Drop duplicates\\nprint(df3.drop_duplicates(keep='first'))\\nprint(df3.drop_duplicates(keep='last'))\\nprint(df3.drop_duplicates(keep=False))\\n# (c) Drop duplicates based on Name\\nprint(df3.drop_duplicates(subset=['Name']))\\nIn\\xa0[11]:\\n12/19/25, 10:31 AM\\nNumpy_&_Pandas\\nlocalhost:8889/lab/tree/Documents/College-MLC/Numpy_%26_Pandas.ipynb\\n3/6\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 3}, page_content='# (d) Count duplicate rows\\nprint(df3.duplicated().sum())\\n# (e) Unique names\\nprint(df3[\\'Name\\'].unique())\\n   Name  Age\\n2  Amit   25\\n4  Riya   30\\n   Name  Age\\n0  Amit   25\\n1  Riya   30\\n3  John   22\\n   Name  Age\\n2  Amit   25\\n3  John   22\\n4  Riya   30\\n   Name  Age\\n3  John   22\\n   Name  Age\\n0  Amit   25\\n1  Riya   30\\n3  John   22\\n2\\n[\\'Amit\\' \\'Riya\\' \\'John\\']\\n# Q8\\ndata = {\\n    \\'Name\\': [\\'Amit\\', \\'Riya\\', \\'John\\', None],\\n    \\'Age\\': [25, np.nan, 22, np.nan],\\n    \\'Salary\\': [50000, 60000, np.nan, np.nan]\\n}\\ndf4 = pd.DataFrame(data)\\n# (a) Detect missing values\\nprint(df4.isna())\\n# (b) Count missing values per column\\nprint(df4.isna().sum())\\n# (c) Drop rows\\nprint(df4.dropna())                     # Any NaN\\nprint(df4.dropna(how=\\'all\\'))            # All NaN\\nprint(df4.dropna(subset=[\\'Age\\',\\'Salary\\']))\\n# (d) Fill missing values\\nprint(df4.fillna(0))\\nprint(df4.fillna({\\'Name\\':\\'Unknown\\'}))\\nprint(df4.fillna(df4.mean(numeric_only=True)))\\nprint(df4.fillna(method=\\'ffill\\'))\\nprint(df4.fillna(method=\\'bfill\\'))\\nprint(df4.interpolate())\\n# (e) Forward fill vs Interpolation\\nprint(\"Forward Fill:\\\\n\", df4.fillna(method=\\'ffill\\'))\\nprint(\"Interpolation:\\\\n\", df4.interpolate())\\nIn\\xa0[12]:\\n12/19/25, 10:31 AM\\nNumpy_&_Pandas\\nlocalhost:8889/lab/tree/Documents/College-MLC/Numpy_%26_Pandas.ipynb\\n4/6'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 4}, page_content='Name    Age  Salary\\n0  False  False   False\\n1  False   True   False\\n2  False  False    True\\n3   True   True    True\\nName      1\\nAge       2\\nSalary    2\\ndtype: int64\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya   NaN  60000.0\\n2  John  22.0      NaN\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya   0.0  60000.0\\n2  John  22.0      0.0\\n3     0   0.0      0.0\\n      Name   Age   Salary\\n0     Amit  25.0  50000.0\\n1     Riya   NaN  60000.0\\n2     John  22.0      NaN\\n3  Unknown   NaN      NaN\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  23.5  60000.0\\n2  John  22.0  55000.0\\n3  None  23.5  55000.0\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  25.0  60000.0\\n2  John  22.0  60000.0\\n3  John  22.0  60000.0\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  22.0  60000.0\\n2  John  22.0      NaN\\n3  None   NaN      NaN\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  23.5  60000.0\\n2  John  22.0  60000.0\\n3  None  22.0  60000.0\\nForward Fill:\\n    Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  25.0  60000.0\\n2  John  22.0  60000.0\\n3  John  22.0  60000.0\\nInterpolation:\\n    Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  23.5  60000.0\\n2  John  22.0  60000.0\\n3  None  22.0  60000.0\\n12/19/25, 10:31 AM\\nNumpy_&_Pandas\\nlocalhost:8889/lab/tree/Documents/College-MLC/Numpy_%26_Pandas.ipynb\\n5/6'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 5}, page_content='C:\\\\Users\\\\drnay\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_10328\\\\4220938775.py:25: FutureWarnin\\ng: DataFrame.fillna with \\'method\\' is deprecated and will raise in a future versio\\nn. Use obj.ffill() or obj.bfill() instead.\\n  print(df4.fillna(method=\\'ffill\\'))\\nC:\\\\Users\\\\drnay\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_10328\\\\4220938775.py:26: FutureWarnin\\ng: DataFrame.fillna with \\'method\\' is deprecated and will raise in a future versio\\nn. Use obj.ffill() or obj.bfill() instead.\\n  print(df4.fillna(method=\\'bfill\\'))\\nC:\\\\Users\\\\drnay\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_10328\\\\4220938775.py:27: FutureWarnin\\ng: DataFrame.interpolate with object dtype is deprecated and will raise in a futu\\nre version. Call obj.infer_objects(copy=False) before interpolating instead.\\n  print(df4.interpolate())\\nC:\\\\Users\\\\drnay\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_10328\\\\4220938775.py:30: FutureWarnin\\ng: DataFrame.fillna with \\'method\\' is deprecated and will raise in a future versio\\nn. Use obj.ffill() or obj.bfill() instead.\\n  print(\"Forward Fill:\\\\n\", df4.fillna(method=\\'ffill\\'))\\nC:\\\\Users\\\\drnay\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_10328\\\\4220938775.py:31: FutureWarnin\\ng: DataFrame.interpolate with object dtype is deprecated and will raise in a futu\\nre version. Call obj.infer_objects(copy=False) before interpolating instead.\\n  print(\"Interpolation:\\\\n\", df4.interpolate())\\n \\nIn\\xa0[\\xa0]:\\n12/19/25, 10:31 AM\\nNumpy_&_Pandas\\nlocalhost:8889/lab/tree/Documents/College-MLC/Numpy_%26_Pandas.ipynb\\n6/6')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "# we can also use PyPDFLoader\n",
    "\n",
    "# to load all the text files from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"data/pdf\",\n",
    "    glob = \"**/*.pdf\",  # Pattern to match the files\n",
    "    loader_cls = PyMuPDFLoader,  # loader class to use\n",
    "    show_progress = False\n",
    ")\n",
    "\n",
    "pdf_documents = dir_loader.load()\n",
    "pdf_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e87b4d4-e18e-47fa-9bf8-be18b6fbcc65",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a1a973-dd73-4eb9-bf2f-c8a7fb7e98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Data Chunks \n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split documents into smaller chunks for better RAG performance.\n",
    "    \n",
    "    Parameters:\n",
    "    - chunk_size: Maximum characters per chunk (adjust based on your LLM)\n",
    "    - chunk_overlap: Characters to overlap between chunks (preserves context)\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, # Each chunk: ~1000 characters\n",
    "        chunk_overlap=chunk_overlap, # 200 chars overlap for context\n",
    "        length_function=len, # How to measure length\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] # Split hierarchy\n",
    "    )\n",
    "    # Actually split the documents\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show what a chunk looks like\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6aeea86-4076-4520-9a21-d594a4baa6b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 31 documents into 62 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: # Q1\n",
      "import pandas as pd\n",
      "# Create dataset\n",
      "data = {\n",
      "    'length': [20, 30, 25, 35, 40],\n",
      "    'breadth': [15, 20, 18, 22, 25],\n",
      "    'price': [2000000, 3500000, 2800000, 4200000, 5500000]\n",
      "}\n",
      "df = pd.DataFra...\n",
      "Metadata: {'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 0}, page_content='# Q1\\nimport pandas as pd\\n# Create dataset\\ndata = {\\n    \\'length\\': [20, 30, 25, 35, 40],\\n    \\'breadth\\': [15, 20, 18, 22, 25],\\n    \\'price\\': [2000000, 3500000, 2800000, 4200000, 5500000]\\n}\\ndf = pd.DataFrame(data)\\n# New feature: total floor area\\ndf[\\'floor_area\\'] = df[\\'length\\'] * df[\\'breadth\\']\\nprint(df)\\nprint(\"\\\\nCorrelation with price:\")\\nprint(df.corr()[\\'price\\'])\\n   length  breadth    price  floor_area\\n0      20       15  2000000         300\\n1      30       20  3500000         600\\n2      25       18  2800000         450\\n3      35       22  4200000         770\\n4      40       25  5500000        1000\\nCorrelation with price:\\nlength        0.991327\\nbreadth       0.994763\\nprice         1.000000\\nfloor_area    0.998616\\nName: price, dtype: float64\\n# Q2\\nimport pandas as pd\\ndata = {\\n    \\'gender\\': [\\'Male\\', \\'Female\\', \\'Female\\', \\'Male\\'],\\n    \\'city\\': [\\'Delhi\\', \\'Mumbai\\', \\'Delhi\\', \\'Chennai\\'],\\n    \\'qualification\\': [\\'Graduate\\', \\'Postgraduate\\', \\'Graduate\\', \\'PhD\\']\\n}\\ndf = pd.DataFrame(data)\\n# One-hot encoding'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 0}, page_content=\"'city': ['Delhi', 'Mumbai', 'Delhi', 'Chennai'],\\n    'qualification': ['Graduate', 'Postgraduate', 'Graduate', 'PhD']\\n}\\ndf = pd.DataFrame(data)\\n# One-hot encoding\\ndf_encoded = pd.get_dummies(df)\\nprint(df_encoded)\\nIn\\xa0[4]:\\nIn\\xa0[3]:\\n12/19/25, 10:54 AM\\nFeature Engineering\\nlocalhost:8889/lab/tree/Documents/College-MLC/Feature Engineering.ipynb\\n1/5\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 1}, page_content=\"gender_Female  gender_Male  city_Chennai  city_Delhi  city_Mumbai  \\\\\\n0          False         True         False        True        False   \\n1           True        False         False       False         True   \\n2           True        False         False        True        False   \\n3          False         True          True       False        False   \\n   qualification_Graduate  qualification_PhD  qualification_Postgraduate  \\n0                    True              False                       False  \\n1                   False              False                        True  \\n2                    True              False                       False  \\n3                   False               True                       False  \\n# Q3\\nimport pandas as pd\\ndata = {\\n    'satisfaction': ['Excellent', 'Good', 'Average', 'Poor', 'Good']\\n}\\ndf = pd.DataFrame(data)\\nmapping = {\\n    'Poor': 1,\\n    'Average': 2,\\n    'Good': 3,\\n    'Excellent': 4\\n}\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 1}, page_content=\"data = {\\n    'satisfaction': ['Excellent', 'Good', 'Average', 'Poor', 'Good']\\n}\\ndf = pd.DataFrame(data)\\nmapping = {\\n    'Poor': 1,\\n    'Average': 2,\\n    'Good': 3,\\n    'Excellent': 4\\n}\\ndf['satisfaction_encoded'] = df['satisfaction'].map(mapping)\\nprint(df)\\n  satisfaction  satisfaction_encoded\\n0    Excellent                     4\\n1         Good                     3\\n2      Average                     2\\n3         Poor                     1\\n4         Good                     3\\n# Q4\\nimport pandas as pd\\ndata = {\\n    'price': [500, 1500, 3000, 7000, 12000]\\n}\\ndf = pd.DataFrame(data)\\ndf['price_category'] = pd.cut(\\n    df['price'],\\n    bins=[0, 2000, 6000, 15000],\\n    labels=['Low', 'Medium', 'High']\\n)\\nprint(df)\\nIn\\xa0[5]:\\nIn\\xa0[6]:\\n12/19/25, 10:54 AM\\nFeature Engineering\\nlocalhost:8889/lab/tree/Documents/College-MLC/Feature Engineering.ipynb\\n2/5\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 2}, page_content='price price_category\\n0    500            Low\\n1   1500            Low\\n2   3000         Medium\\n3   7000           High\\n4  12000           High\\n# Q5\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom sklearn.decomposition import PCA\\n# Numeric dataset\\nX = np.random.rand(100, 5)\\npca = PCA(n_components=2)\\nX_pca = pca.fit_transform(X)\\nplt.figure()\\nplt.scatter(X_pca[:, 0], X_pca[:, 1])\\nplt.title(\"PCA - 2 Components\")\\nplt.xlabel(\"PC1\")\\nplt.ylabel(\"PC2\")\\nplt.grid(True, linestyle=\\'--\\', alpha=0.5)\\nplt.show()\\n# Q6\\nimport numpy as np\\n# Generate numeric dataset\\nIn\\xa0[3]:\\nIn\\xa0[8]:\\n12/19/25, 10:54 AM\\nFeature Engineering\\nlocalhost:8889/lab/tree/Documents/College-MLC/Feature Engineering.ipynb\\n3/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 3}, page_content='X = np.random.rand(5, 4)\\n# SVD\\nU, S, Vt = np.linalg.svd(X, full_matrices=False)\\n# Reconstruct matrix\\nX_approx = U @ np.diag(S) @ Vt\\nprint(\"Original Matrix:\\\\n\", X)\\nprint(\"\\\\nReconstructed Matrix:\\\\n\", X_approx)\\nOriginal Matrix:\\n [[0.65438659 0.76322352 0.63328156 0.13640117]\\n [0.55989237 0.99178825 0.59773302 0.14767012]\\n [0.40366844 0.54514935 0.24724823 0.24567122]\\n [0.19468232 0.86078516 0.88215269 0.73651777]\\n [0.77669607 0.491355   0.7887976  0.93835776]]\\nReconstructed Matrix:\\n [[0.65438659 0.76322352 0.63328156 0.13640117]\\n [0.55989237 0.99178825 0.59773302 0.14767012]\\n [0.40366844 0.54514935 0.24724823 0.24567122]\\n [0.19468232 0.86078516 0.88215269 0.73651777]\\n [0.77669607 0.491355   0.7887976  0.93835776]]\\n# Q7\\nfrom sklearn.datasets import load_iris\\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\\n# Load labeled dataset\\ndata = load_iris()\\nX = data.data\\ny = data.target\\nlda = LinearDiscriminantAnalysis(n_components=2)\\nX_lda = lda.fit_transform(X, y)'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 3}, page_content='# Load labeled dataset\\ndata = load_iris()\\nX = data.data\\ny = data.target\\nlda = LinearDiscriminantAnalysis(n_components=2)\\nX_lda = lda.fit_transform(X, y)\\nprint(\"LDA transformed shape:\", X_lda.shape)\\nLDA transformed shape: (150, 2)\\n# Q8\\nfrom sklearn.datasets import load_iris\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score\\ndata = load_iris()\\nX = data.data\\ny = data.target\\n# Full dataset\\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\\nmodel_full = LogisticRegression(max_iter=200)\\nmodel_full.fit(X_train, y_train)\\nacc_full = accuracy_score(y_test, model_full.predict(X_test))\\n# Subset of columns\\nX_subset = X[:, :2]\\nIn\\xa0[9]:\\nIn\\xa0[10]:\\n12/19/25, 10:54 AM\\nFeature Engineering\\nlocalhost:8889/lab/tree/Documents/College-MLC/Feature Engineering.ipynb\\n4/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 4}, page_content='X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_subset, y, random_\\nmodel_subset = LogisticRegression(max_iter=200)\\nmodel_subset.fit(X_train_s, y_train_s)\\nacc_subset = accuracy_score(y_test_s, model_subset.predict(X_test_s))\\nprint(\"Accuracy (Full features):\", acc_full)\\nprint(\"Accuracy (Subset features):\", acc_subset)\\nAccuracy (Full features): 1.0\\nAccuracy (Subset features): 0.8421052631578947\\n# Q9\\nimport pandas as pd\\nimport numpy as np\\n# Create correlated dataset\\nnp.random.seed(0)\\nx1 = np.random.rand(100)\\nx2 = x1 * 0.9 + np.random.rand(100) * 0.1\\nx3 = np.random.rand(100)\\ndf = pd.DataFrame({\\n    \\'feature1\\': x1,\\n    \\'feature2\\': x2,\\n    \\'feature3\\': x3\\n})\\n# Correlation matrix\\ncorr = df.corr()\\nprint(\"Correlation Matrix:\\\\n\", corr)\\n# Drop highly correlated feature\\ndf_reduced = df.drop(\\'feature2\\', axis=1)\\nprint(\"\\\\nReduced Dataset:\\\\n\", df_reduced.head())\\nCorrelation Matrix:\\n           feature1  feature2  feature3\\nfeature1  1.000000  0.994307 -0.036512'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:17+00:00', 'source': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Feature Engi (3) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Feature Engi (3) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:17+00:00', 'trapped': '', 'modDate': \"D:20251219052417+00'00'\", 'creationDate': \"D:20251219052417+00'00'\", 'page': 4}, page_content='df_reduced = df.drop(\\'feature2\\', axis=1)\\nprint(\"\\\\nReduced Dataset:\\\\n\", df_reduced.head())\\nCorrelation Matrix:\\n           feature1  feature2  feature3\\nfeature1  1.000000  0.994307 -0.036512\\nfeature2  0.994307  1.000000 -0.049809\\nfeature3 -0.036512 -0.049809  1.000000\\nReduced Dataset:\\n    feature1  feature3\\n0  0.548814  0.311796\\n1  0.715189  0.696343\\n2  0.602763  0.377752\\n3  0.544883  0.179604\\n4  0.423655  0.024679\\n \\nIn\\xa0[11]:\\nIn\\xa0[\\xa0]:\\n12/19/25, 10:54 AM\\nFeature Engineering\\nlocalhost:8889/lab/tree/Documents/College-MLC/Feature Engineering.ipynb\\n5/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'file_path': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'INFLUCRAFT PRIVATE LIMITED-One Page Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='INFLUCRAFT PRIVATE LIMITED \\nDomain : Creator Economy | Creator Tech | AI + SAAS \\nCompany Overview \\nInflucraft is a Creator-Tech platform that helps creators run their work like a real business. \\nToday, creator campaigns are managed through WhatsApp, emails, and PDFs. This leads to \\nmessy workflows, delayed approvals, payment confusion, and zero automation. Creators \\ndont have proper systems to manage campaigns, teams, content, and money in one place. \\nInflucraft fixes this by giving creators a single intelligent platform to manage campaigns, \\ncontent, teams, and payments using AI-driven automation.\\u200b\\nInflucraft is not a creator marketplace or discovery platform. \\nWhat Does Influcraft Do? \\nInflucraft provides creators and brands a structured system to: \\n\\u200b Execute campaigns end-to-end \\n\\u200b Track deliverables and approvals \\n\\u200b Automate workflows using AI \\n\\u200b Manage teams and content \\n\\u200b Handle payments transparently \\nIt replaces chaos with systems. \\n \\nPlatform & Core Features'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'file_path': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'INFLUCRAFT PRIVATE LIMITED-One Page Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='\\u200b Track deliverables and approvals \\n\\u200b Automate workflows using AI \\n\\u200b Manage teams and content \\n\\u200b Handle payments transparently \\nIt replaces chaos with systems. \\n \\nPlatform & Core Features \\n1.  AI Workflow Automation (Core Engine) \\nCreators or brands can start a campaign by: \\n\\u200b Uploading the campaign brief (PDF, email, text), or \\n\\u200b Using a drag-and-drop workflow builder. \\nInflucrafts AI then: \\n\\u200b Extracts deliverables \\n\\u200b Builds structured workflows'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'file_path': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'INFLUCRAFT PRIVATE LIMITED-One Page Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1}, page_content='\\u200b Tracks deliverables from both creator and brand side \\n\\u200b Assigns tasks (integrated with Creator Studio if used) \\n\\u200b Sets timelines and milestones \\n\\u200b Tracks progress in real time \\nAfter both sides agree on terms: \\n\\u200b The brand deposits the full campaign amount into Influcrafts escrow \\n\\u200b Payments are linked to deliverables \\n\\u200b As deliverables are verified, the system auto-releases payments to the creator \\nThis creates a trust loop:\\u200b\\n Deliverables  Verification  Auto Payment  Trust \\n  \\n2.  Creator CMS \\nCreators manage their entire digital presence from one dashboard: \\n\\u200b Blogs \\n\\u200b Newsletters \\n\\u200b Content calendar \\n\\u200b Content scheduling \\n\\u200b Personalized and domain-mapped websites \\n\\u200b Link-in-bio \\n\\u200b URL shortener \\n3.  Creator Studio \\nFor creators who run teams: \\n\\u200b Editors, designers, writers, managers \\n\\u200b Task assignment and tracking \\n\\u200b File sharing \\n\\u200b Team collaboration \\n\\u200b Deep integration with AI Workflow Automation \\n  \\n \\n4.  Financial Wallet & Ledger'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'file_path': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'INFLUCRAFT PRIVATE LIMITED-One Page Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1}, page_content='\\u200b Editors, designers, writers, managers \\n\\u200b Task assignment and tracking \\n\\u200b File sharing \\n\\u200b Team collaboration \\n\\u200b Deep integration with AI Workflow Automation \\n  \\n \\n4.  Financial Wallet & Ledger \\n\\u200b Escrow-based campaign payments \\n\\u200b Transparent income tracking \\n\\u200b Automated payouts \\n\\u200b Business-grade financial system for creators'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'file_path': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'INFLUCRAFT PRIVATE LIMITED-One Page Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2}, page_content='5.  Unified Creator ID & SSO \\n\\u200b One login for all Influcraft tools \\n\\u200b Easy future product expansion \\n\\u200b Unified identity across workflows \\nVision \\nTo elevate creators into businesses by giving them the same systems, automation, and \\nfinancial clarity that companies have. \\nLong-term, Influcraft aims to become the infrastructure layer of the creator economy. \\nProblem We Are Solving \\nCreators face: \\n\\u200b Scattered tools \\n\\u200b Manual coordination \\n\\u200b No financial clarity \\n\\u200b No business-grade systems \\nBrands face: \\n\\u200b No visibility into real workflows \\n\\u200b Delayed approvals \\n\\u200b Poor tracking of deliverables \\nThere is no unified Creator-Tech platform in India that manages campaigns, content, teams, \\nanalytics, and payments together. \\n \\n \\nOur Solution \\nInflucraft offers: \\n\\u200b AI-first workflow automation \\n\\u200b Business-grade creator systems \\n\\u200b End-to-end campaign execution \\n\\u200b Financial trust layer \\n\\u200b Data-driven creator growth'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'file_path': 'data\\\\pdf\\\\INFLUCRAFT PRIVATE LIMITED-One Page Summary.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'INFLUCRAFT PRIVATE LIMITED-One Page Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3}, page_content='Why Influcraft? \\nThe creator economy runs on chaos.\\u200b\\n Influcraft is building systems. \\nSo creators stop being freelancers \\u200b\\n And start being businesses. \\n    \\n Subodh Kumar Pradhan ,Purusottam Mohanta \\n Founders, Influcraft'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'file_path': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'Influcraft  Executive Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='Influcraft  Executive Summary \\nDomain: Creator Economy | Creator-Tech | AI + SaaS \\nCompany Overview \\nInflucraft is a Creator-Tech platform that helps creators run their work like a real business. \\nToday, most creator campaigns are managed through WhatsApp, emails, and PDFs. This \\ncreates messy workflows, delayed approvals, payment confusion, and zero automation. \\nCreators do not have proper systems to manage campaigns, teams, content, and money in \\none place. Influcraft fixes this by giving creators a single intelligent platform to manage \\ncampaigns, content, teams, and payments using AI-driven automation. Influcraft is not a \\ncreator marketplace or discovery platform. \\nWhat Does Influcraft Do? \\nInflucraft provides creators and brands a structured system to execute campaigns \\nend-to-end. It helps track deliverables and approvals, automate workflows using AI, manage \\nteams and content, and handle payments transparently. In simple words, Influcraft replaces \\nchaos with systems.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'file_path': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'Influcraft  Executive Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='teams and content, and handle payments transparently. In simple words, Influcraft replaces \\nchaos with systems. \\nPlatform & Core Features \\nThe core of Influcraft is its AI Workflow Automation engine. Creators or brands can start a \\ncampaign by uploading a campaign brief such as a PDF or by using a drag-and-drop \\nworkflow builder. Influcrafts AI reads the brief, extracts deliverables, builds a structured \\nworkflow, assigns tasks, sets timelines, and tracks progress from both the creator and brand \\nside. This system is directly integrated with Creator Studio if the creator is working with a \\nteam. Once both sides agree on the terms and deliverables, the brand deposits the full \\ncampaign amount into Influcrafts escrow system. Payments are linked to deliverables, and \\nas soon as the deliverables and conditions are met, the system automatically releases the \\npayment to the creator. \\nInflucraft also provides a Creator CMS where creators manage their entire digital presence'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'file_path': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'Influcraft  Executive Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='payment to the creator. \\nInflucraft also provides a Creator CMS where creators manage their entire digital presence \\nfrom one dashboard. They can run blogs, newsletters, content scheduling, and content \\ncalendars, along with personalized and domain-mapped websites, link-in-bio pages, and \\nURL shorteners. This allows creators to operate like a real media business instead of using \\nmultiple disconnected tools. \\nFor creators who manage teams, Influcraft offers Creator Studio. It is a space where editors, \\ndesigners, writers, and managers can collaborate. It supports task assignment, file sharing, \\nteam communication, and is deeply integrated with the AI Workflow Automation system so \\nthat campaign work and team work stay in sync.It supports escrow-based campaign'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'file_path': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'Influcraft  Executive Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1}, page_content='payments, transparent income tracking, automated payouts, and a business-grade financial \\nstructure for creators.  \\nAlong with this, Influcraft provides a Unified Creator ID and Single Sign-On so creators use \\none login across all tools, making future expansion of features simple and seamless. \\nVision \\nInflucrafts vision is to elevate creators into businesses by giving them the same systems, \\nautomation, and financial clarity that companies have. In the long term, Influcraft aims to \\nbecome the infrastructure layer of the creator economy. \\nProblem We Are Solving \\nCreators today face scattered tools, manual coordination, no financial clarity, and no \\nbusiness-grade systems. Brands face poor visibility into real workflows, delayed approvals, \\nand weak tracking of deliverables. There is no unified Creator-Tech platform in India that \\nmanages campaigns, content, teams, analytics, and payments together in one system. \\nOur Solution'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'file_path': 'data\\\\pdf\\\\Influcraft  Executive Summary.pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'Influcraft  Executive Summary', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1}, page_content='and weak tracking of deliverables. There is no unified Creator-Tech platform in India that \\nmanages campaigns, content, teams, analytics, and payments together in one system. \\nOur Solution \\nInflucraft solves this by offering AI-first workflow automation, business-grade creator \\nsystems, end-to-end campaign execution, a financial trust layer, and data-driven tools for \\ncreator growth  all inside one unified platform. \\nWhy Influcraft? \\nThe creator economy today runs on chaos. Influcraft is building systems. So creators stop \\nbeing freelancers  and start being businesses. \\n \\n \\n \\n \\n \\n \\n \\nSubodh Kumar Pradhan \\nFounder \\nPurusottam Mohanta \\nCo-Founder'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:21:50+00:00', 'source': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Matplotlib.i (2) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:21:50+00:00', 'trapped': '', 'modDate': \"D:20251219052150+00'00'\", 'creationDate': \"D:20251219052150+00'00'\", 'page': 0}, page_content='# Q1\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n# Student data\\ndata = {\\n    \\'Name\\': [\\'Rishika Batra\\', \\'Waseem Ali\\', \\'Kulpreet Singh\\', \\'Annie Mathews\\', \\'\\n             \\'Naveen Gupta\\', \\'Taleem Ahmed\\', \\'Pragati Nigam\\', \\'Usman Abbas\\'],\\n    \\'English\\': [95, 95, 78, 88, 95, 82, 73, 80, 92],\\n    \\'Maths\\': [95, 76, 81, 63, 55, 55, 49, 50, 43],\\n    \\'Hindi\\': [90, 79, 75, 67, 51, 63, 54, 51, 51],\\n    \\'Science\\': [94, 77, 76, 77, 59, 56, 60, 54, 48],\\n    \\'Social Studies\\': [95, 89, 88, 80, 80, 74, 77, 76, 69]\\n}\\ndf = pd.DataFrame(data)\\n# Boxplot\\ndf.drop(\\'Name\\', axis=1).plot(kind=\\'box\\', figsize=(10,6), title=\\'Student Performa\\nplt.ylabel(\"Marks\")\\nplt.grid(True, linestyle=\\'--\\', alpha=0.8)\\nplt.show()\\n# Q2\\nimport matplotlib.pyplot as plt\\ndiscounts = [10, 20, 30, 40, 50]\\nsales = [40000, 45000, 48000, 50000, 100000]\\nplt.scatter(discounts, sales, color=\\'green\\', marker=\\'o\\')\\nplt.title(\"Discount vs Sales for Designer Bags and Wallets\")\\nplt.xlabel(\"Discount (%)\")\\nplt.ylabel(\"Sales (Rs.)\")\\nIn\\xa0[22]:\\nIn\\xa0[14]:'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:21:50+00:00', 'source': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Matplotlib.i (2) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:21:50+00:00', 'trapped': '', 'modDate': \"D:20251219052150+00'00'\", 'creationDate': \"D:20251219052150+00'00'\", 'page': 0}, page_content='plt.scatter(discounts, sales, color=\\'green\\', marker=\\'o\\')\\nplt.title(\"Discount vs Sales for Designer Bags and Wallets\")\\nplt.xlabel(\"Discount (%)\")\\nplt.ylabel(\"Sales (Rs.)\")\\nIn\\xa0[22]:\\nIn\\xa0[14]:\\n12/19/25, 10:51 AM\\nMatplotlib\\nlocalhost:8889/lab/tree/Documents/College-MLC/Matplotlib.ipynb\\n1/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:21:50+00:00', 'source': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Matplotlib.i (2) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:21:50+00:00', 'trapped': '', 'modDate': \"D:20251219052150+00'00'\", 'creationDate': \"D:20251219052150+00'00'\", 'page': 1}, page_content='plt.grid(True, linestyle=\\'--\\', alpha=0.4)\\nplt.show()\\n# Q3 - (a)\\nimport pandas as pd\\nurl = \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mp\\ncolumns = [\\'mpg\\',\\'cylinders\\',\\'displacement\\',\\'horsepower\\',\\'weight\\',\\n           \\'acceleration\\',\\'model_year\\',\\'origin\\',\\'car_name\\']\\ndf = pd.read_csv(url, sep=\\'\\\\s+\\', names=columns, na_values=\\'?\\')\\nprint(\"Original shape:\", df.shape)\\ndf = df.dropna()\\ndf[\\'horsepower\\'] = pd.to_numeric(df[\\'horsepower\\'])\\nprint(\"Cleaned shape:\", df.shape)\\nprint(df.head())\\nIn\\xa0[6]:\\n12/19/25, 10:51 AM\\nMatplotlib\\nlocalhost:8889/lab/tree/Documents/College-MLC/Matplotlib.ipynb\\n2/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:21:50+00:00', 'source': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Matplotlib.i (2) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:21:50+00:00', 'trapped': '', 'modDate': \"D:20251219052150+00'00'\", 'creationDate': \"D:20251219052150+00'00'\", 'page': 2}, page_content='Original shape: (398, 9)\\nCleaned shape: (392, 9)\\n    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\\\\n0  18.0          8         307.0       130.0  3504.0          12.0   \\n1  15.0          8         350.0       165.0  3693.0          11.5   \\n2  18.0          8         318.0       150.0  3436.0          11.0   \\n3  16.0          8         304.0       150.0  3433.0          12.0   \\n4  17.0          8         302.0       140.0  3449.0          10.5   \\n   model_year  origin                   car_name  \\n0          70       1  chevrolet chevelle malibu  \\n1          70       1          buick skylark 320  \\n2          70       1         plymouth satellite  \\n3          70       1              amc rebel sst  \\n4          70       1                ford torino  \\n# Q3 - b\\nimport matplotlib.pyplot as plt\\nplt.figure(figsize=(8,6))\\nplt.scatter(df[\\'horsepower\\'], df[\\'mpg\\'], alpha=0.7, color=\\'blue\\')\\nplt.xlabel(\"Horsepower\")\\nplt.ylabel(\"Miles per Gallon (MPG)\")\\nplt.title(\"Horsepower vs MPG\")'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:21:50+00:00', 'source': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Matplotlib.i (2) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:21:50+00:00', 'trapped': '', 'modDate': \"D:20251219052150+00'00'\", 'creationDate': \"D:20251219052150+00'00'\", 'page': 2}, page_content='plt.figure(figsize=(8,6))\\nplt.scatter(df[\\'horsepower\\'], df[\\'mpg\\'], alpha=0.7, color=\\'blue\\')\\nplt.xlabel(\"Horsepower\")\\nplt.ylabel(\"Miles per Gallon (MPG)\")\\nplt.title(\"Horsepower vs MPG\")\\nplt.grid(True, linestyle=\\'--\\', alpha=0.6)\\nplt.show()\\n# Q3 - c\\nplt.figure(figsize=(8,6))\\nplt.hist(df[\\'mpg\\'], bins=18, color=\\'skyblue\\', edgecolor=\\'black\\')\\nIn\\xa0[7]:\\nIn\\xa0[15]:\\n12/19/25, 10:51 AM\\nMatplotlib\\nlocalhost:8889/lab/tree/Documents/College-MLC/Matplotlib.ipynb\\n3/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:21:50+00:00', 'source': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Matplotlib.i (2) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:21:50+00:00', 'trapped': '', 'modDate': \"D:20251219052150+00'00'\", 'creationDate': \"D:20251219052150+00'00'\", 'page': 3}, page_content='plt.xlabel(\"Miles per Gallon (MPG)\")\\nplt.ylabel(\"Frequency\")\\nplt.title(\"Distribution of MPG\")\\nplt.grid(True, linestyle=\\'--\\', alpha=0.8)\\nplt.show()\\n# Q3 - d\\nplt.figure(figsize=(8,6))\\ndf.boxplot(column=\\'mpg\\', by=\\'cylinders\\')\\nplt.xlabel(\"Number of Cylinders\")\\nplt.ylabel(\"Miles per Gallon (MPG)\")\\nplt.title(\"MPG Distribution by Cylinders\")\\nplt.suptitle(\"\")  # remove automatic title\\nplt.grid(True, linestyle=\\'--\\', alpha=0.5)\\nplt.show()\\n<Figure size 800x600 with 0 Axes>\\nIn\\xa0[18]:\\n12/19/25, 10:51 AM\\nMatplotlib\\nlocalhost:8889/lab/tree/Documents/College-MLC/Matplotlib.ipynb\\n4/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:21:50+00:00', 'source': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Matplotlib.i (2) - JupyterLab.pdf', 'total_pages': 5, 'format': 'PDF 1.4', 'title': 'Matplotlib.i (2) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:21:50+00:00', 'trapped': '', 'modDate': \"D:20251219052150+00'00'\", 'creationDate': \"D:20251219052150+00'00'\", 'page': 4}, page_content='In\\xa0[\\xa0]:\\n12/19/25, 10:51 AM\\nMatplotlib\\nlocalhost:8889/lab/tree/Documents/College-MLC/Matplotlib.ipynb\\n5/5'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 0}, page_content='# Q1\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\ndata = pd.read_csv(\\'auto_mpg.csv\\')\\nprint(data.shape)\\ntrain_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\\nprint(\"\\\\nTraining set:\")\\nprint(train_df)\\nprint(\"Training set length:\", len(train_df))\\nprint(\"\\\\nTest set:\")\\nprint(test_df)\\nprint(\"Test set length:\", len(test_df))\\nIn\\xa0[3]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n1/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 1}, page_content='(398, 9)\\nTraining set:\\n      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\\\\n3    16.0          8         304.0       150.0  3433.0          12.0   \\n18   27.0          4          97.0        88.0  2130.0          14.5   \\n376  37.0          4          91.0        68.0  2025.0          18.2   \\n248  36.1          4          91.0        60.0  1800.0          16.4   \\n177  23.0          4         115.0        95.0  2694.0          15.0   \\n..    ...        ...           ...         ...     ...           ...   \\n71   19.0          3          70.0        97.0  2330.0          13.5   \\n106  12.0          8         350.0       180.0  4499.0          12.5   \\n270  21.1          4         134.0        95.0  2515.0          14.8   \\n348  37.7          4          89.0        62.0  2050.0          17.3   \\n102  26.0          4          97.0        46.0  1950.0          21.0   \\n     model_year  origin                   car_name  \\n3            70       1              amc rebel sst'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 1}, page_content='102  26.0          4          97.0        46.0  1950.0          21.0   \\n     model_year  origin                   car_name  \\n3            70       1              amc rebel sst  \\n18           70       3               datsun pl510  \\n376          82       3         mazda glc custom l  \\n248          78       3           honda civic cvcc  \\n177          75       2                 audi 100ls  \\n..          ...     ...                        ...  \\n71           72       3            mazda rx2 coupe  \\n106          73       1   oldsmobile vista cruiser  \\n270          78       3  toyota celica gt liftback  \\n348          81       3              toyota tercel  \\n102          73       2    volkswagen super beetle  \\n[318 rows x 9 columns]\\nTraining set length: 318\\nTest set:\\n      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\\\\n198  33.0          4          91.0        53.0  1795.0          17.4   \\n396  28.0          4         120.0        79.0  2625.0          18.6'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 1}, page_content='198  33.0          4          91.0        53.0  1795.0          17.4   \\n396  28.0          4         120.0        79.0  2625.0          18.6   \\n33   19.0          6         232.0       100.0  2634.0          13.0   \\n208  13.0          8         318.0       150.0  3940.0          13.2   \\n93   14.0          8         318.0       150.0  4237.0          14.5   \\n..    ...        ...           ...         ...     ...           ...   \\n249  19.9          8         260.0       110.0  3365.0          15.5   \\n225  17.5          6         250.0       110.0  3520.0          16.4   \\n367  28.0          4         112.0        88.0  2605.0          19.6   \\n175  29.0          4          90.0        70.0  1937.0          14.0   \\n285  17.0          8         305.0       130.0  3840.0          15.4   \\n     model_year  origin                           car_name  \\n198          76       3                        honda civic  \\n396          82       1                        ford ranger'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 1}, page_content='model_year  origin                           car_name  \\n198          76       3                        honda civic  \\n396          82       1                        ford ranger  \\n33           71       1                        amc gremlin  \\n208          76       1         plymouth volare premier v8  \\n93           73       1           plymouth fury gran sedan  \\n..          ...     ...                                ...  \\n249          78       1  oldsmobile cutlass salon brougham  \\n225          77       1                 chevrolet concours  \\n367          82       1                 chevrolet cavalier  \\n175          75       2                  volkswagen rabbit  \\n285          79       1          chevrolet caprice classic  \\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n2/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 2}, page_content='[80 rows x 9 columns]\\nTest set length: 80\\n# Q2\\nfrom sklearn.model_selection import KFold\\n# Load dataset\\ndf = pd.read_csv(\"btissue.csv\")\\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\\nfor fold, (train_index, test_index) in enumerate(kf.split(df)):\\n    print(f\"\\\\nFold {fold}\")\\n    print(\"Training indices:\", train_index)\\n    print(\"Test indices:\", test_index)\\n    # 3rd iteration (fold index = 2)\\n    if fold == 2:\\n        train_set = df.iloc[train_index]\\n        test_set = df.iloc[test_index]\\n        print(\"\\\\nTraining set (3rd fold):\")\\n        print(train_set)\\n        print(\"Training set length:\", len(train_set))\\n        print(\"\\\\nTest set (3rd fold):\")\\n        print(test_set)\\n        print(\"Test set length:\", len(test_set))\\nIn\\xa0[10]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n3/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 3}, page_content='Fold 0\\nTraining indices: [  1   2   3   5   6   7   8   9  13  14  15  16  17  19  20  2\\n1  22  23\\n  24  25  26  27  28  29  31  32  34  35  36  37  38  39  40  41  43  45\\n  46  48  49  50  51  52  53  54  56  57  58  59  60  61  62  63  66  68\\n  69  70  71  72  73  74  75  76  77  82  83  84  85  86  87  88  89  90\\n  91  92  94  95  96  98  99 101 102 103 104 105]\\nTest indices: [  0   4  10  11  12  18  30  33  42  44  47  55  64  65  67  78  7\\n9  80\\n  81  93  97 100]\\nFold 1\\nTraining indices: [  0   1   2   3   4   6   7   8  10  11  12  13  14  17  18  1\\n9  20  21\\n  23  24  25  27  29  30  32  33  34  37  38  41  42  43  44  46  47  48\\n  49  50  51  52  54  55  56  57  58  59  60  61  63  64  65  66  67  68\\n  69  70  71  72  74  75  78  79  80  81  82  83  84  85  86  87  89  90\\n  91  92  93  94  96  97  98  99 100 101 102 103 105]\\nTest indices: [  5   9  15  16  22  26  28  31  35  36  39  40  45  53  62  73  7\\n6  77\\n  88  95 104]\\nFold 2'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 3}, page_content='91  92  93  94  96  97  98  99 100 101 102 103 105]\\nTest indices: [  5   9  15  16  22  26  28  31  35  36  39  40  45  53  62  73  7\\n6  77\\n  88  95 104]\\nFold 2\\nTraining indices: [  0   1   2   4   5   9  10  11  12  14  15  16  18  20  21  2\\n2  23  26\\n  28  29  30  31  32  33  35  36  37  39  40  41  42  44  45  46  47  48\\n  50  51  52  53  54  55  57  58  59  60  61  62  63  64  65  67  68  71\\n  72  73  74  75  76  77  78  79  80  81  82  83  84  86  87  88  89  91\\n  92  93  94  95  96  97  99 100 101 102 103 104 105]\\nTest indices: [ 3  6  7  8 13 17 19 24 25 27 34 38 43 49 56 66 69 70 85 90 98]\\nTraining set (3rd fold):\\n              I0     PA500       HFS           DA           Area        A/DA  \\\\\\n0     524.794072  0.187448  0.032114   228.800228    6843.598481   29.910803   \\n1     330.000000  0.226893  0.265290   121.154201    3163.239472   26.109202   \\n2     551.879287  0.232478  0.063530   264.804935   11888.391830   44.894903'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 3}, page_content='1     330.000000  0.226893  0.265290   121.154201    3163.239472   26.109202   \\n2     551.879287  0.232478  0.063530   264.804935   11888.391830   44.894903   \\n4     362.831266  0.200713  0.244346   124.912559    3290.462446   26.342127   \\n5     389.872978  0.150098  0.097738   118.625814    2475.557078   20.868620   \\n..           ...       ...       ...          ...            ...         ...   \\n101  2000.000000  0.106989  0.105418   520.222649   40087.920980   77.059161   \\n102  2600.000000  0.200538  0.208043  1063.441427  174480.476200  164.071543   \\n103  1600.000000  0.071908 -0.066323   436.943603   12655.342130   28.963331   \\n104  2300.000000  0.045029  0.136834   185.446044    5086.292497   27.427344   \\n105  2600.000000  0.069988  0.048869   745.474369   39845.773700   53.450226   \\n         Max IP          DR            P class  \\n0     60.204880  220.737212   556.828334   car  \\n1     69.717361   99.084964   400.225776   car  \\n2     77.793297  253.785300   656.769449   car'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 3}, page_content='Max IP          DR            P class  \\n0     60.204880  220.737212   556.828334   car  \\n1     69.717361   99.084964   400.225776   car  \\n2     77.793297  253.785300   656.769449   car  \\n4     69.389389  103.866552   424.796503   car  \\n5     49.757149  107.686164   429.385788   car  \\n..          ...         ...          ...   ...  \\n101  204.090347  478.517223  2088.648870   adi  \\n102  418.687286  977.552367  2664.583623   adi  \\n103  103.732704  432.129749  1475.371534   adi  \\n104  178.691742   49.593290  2480.592151   adi  \\n105  154.122604  729.368395  2545.419744   adi  \\n[85 rows x 10 columns]\\nTraining set length: 85\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n4/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 4}, page_content='Test set (3rd fold):\\n             I0     PA500       HFS          DA          Area       A/DA  \\\\\\n3    380.000000  0.240855  0.286234  137.640111   5402.171180  39.248524   \\n6    290.455141  0.144164  0.053058   74.635067   1189.545213  15.938154   \\n7    275.677393  0.153938  0.187797   91.527893   1756.234837  19.187974   \\n8    470.000000  0.213105  0.225497  184.590057   8185.360837  44.343455   \\n13   366.942379  0.280125  0.252026  172.745554   7064.815909  40.897237   \\n17   300.000000  0.190066  0.166853   97.108130   3039.561303  31.300791   \\n19   294.474846  0.206647  0.467748  194.871035   5541.256126  28.435504   \\n24   352.656447  0.121999  0.090757   68.527846   1066.157846  15.558024   \\n25   243.293976  0.039968  0.067021   68.544778    383.928453   5.601134   \\n27   250.000000  0.068068 -0.015359   57.172431    652.901349  11.419863   \\n34   155.000000  0.172788  0.118682   38.940168    415.111601  10.660242'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 4}, page_content='27   250.000000  0.068068 -0.015359   57.172431    652.901349  11.419863   \\n34   155.000000  0.172788  0.118682   38.940168    415.111601  10.660242   \\n38   435.093167  0.076969  0.161268  123.597538   1342.277648  10.860068   \\n43   252.000000  0.106116  0.031416   38.544210    493.790423  12.811014   \\n49   544.654349  0.063705  0.002094  100.788080   1189.290233  11.799910   \\n56   152.000000  0.165806  0.227591   34.219550     94.354328   2.757322   \\n66   176.000000  0.089884  0.076794   20.588524     79.705425   3.871352   \\n69   103.000000  0.158127  0.291819   23.754811     78.258474   3.294426   \\n70  1724.089894  0.052709 -0.020944  404.126208   3053.966890   7.556963   \\n85  1800.000000  0.034208  0.042586  301.060351   4406.154331  14.635452   \\n90  1850.000000  0.079149  0.069470  253.621455  13113.203090  51.703840   \\n98  2329.840138  0.066148  0.353255  377.253368  25369.039920  67.246689   \\n        Max IP          DR            P class'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 4}, page_content='90  1850.000000  0.079149  0.069470  253.621455  13113.203090  51.703840   \\n98  2329.840138  0.066148  0.353255  377.253368  25369.039920  67.246689   \\n        Max IP          DR            P class  \\n3    88.758446  105.198568   493.701814   car  \\n6    35.703331   65.541324   330.267293   car  \\n7    39.305183   82.658682   331.588302   car  \\n8    84.482483  164.122511   603.315715   car  \\n13   75.604324  155.322285   471.588195   car  \\n17   51.353973   82.418192   387.078228   car  \\n19   36.765797  191.804890   445.513299   car  \\n24   43.691925   52.792817   382.733186   fad  \\n25    9.991348   67.816656   263.640761   fad  \\n27   17.776981   55.791270   278.308615   fad  \\n34   25.836502   29.134376   184.817041   fad  \\n38   37.384724  117.808038   433.202322   mas  \\n43   25.541145   28.867040   280.658299   mas  \\n49   29.412222   96.580150   553.358210   mas  \\n56   31.279278   13.877478   180.609553   gla  \\n66   18.226492    9.575088   191.992878   gla'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 4}, page_content='43   25.541145   28.867040   280.658299   mas  \\n49   29.412222   96.580150   553.358210   mas  \\n56   31.279278   13.877478   180.609553   gla  \\n66   18.226492    9.575088   191.992878   gla  \\n69   22.323603    8.120826   124.978561   gla  \\n70   71.427589  399.194244  1489.386712   con  \\n85   67.625328  293.366920  1742.375702   adi  \\n90  160.065460  196.730498  1916.985365   adi  \\n98  336.075165  171.387227  2686.435346   adi  \\nTest set length: 21\\nFold 3\\nTraining indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  1\\n5  16  17\\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  33  34  35  36\\n  37  38  39  40  42  43  44  45  47  49  51  52  53  55  56  60  62  64\\n  65  66  67  69  70  71  73  74  76  77  78  79  80  81  82  85  86  87\\n  88  89  90  92  93  94  95  96  97  98 100 102 104]\\nTest indices: [ 32  41  46  48  50  54  57  58  59  61  63  68  72  75  83  84  9\\n1  99\\n 101 103 105]\\n12/19/25, 10:54 AM\\nModel Training and Evaluation'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 4}, page_content='Test indices: [ 32  41  46  48  50  54  57  58  59  61  63  68  72  75  83  84  9\\n1  99\\n 101 103 105]\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n5/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 5}, page_content='Fold 4\\nTraining indices: [  0   3   4   5   6   7   8   9  10  11  12  13  15  16  17  1\\n8  19  22\\n  24  25  26  27  28  30  31  32  33  34  35  36  38  39  40  41  42  43\\n  44  45  46  47  48  49  50  53  54  55  56  57  58  59  61  62  63  64\\n  65  66  67  68  69  70  72  73  75  76  77  78  79  80  81  83  84  85\\n  88  90  91  93  95  97  98  99 100 101 103 104 105]\\nTest indices: [  1   2  14  20  21  23  29  37  51  52  60  71  74  82  86  87  8\\n9  92\\n  94  96 102]\\n# Q3\\nfrom sklearn.utils import resample\\n# Load dataset\\ndf = pd.read_csv(\"btissue.csv\")\\n# 1. Extract predictors (assuming last column is target)\\nX = df.iloc[:, :-1]\\n# 2. Bootstrap sample of size 100\\nbootstrap_sample = resample(X, n_samples=100, random_state=42)\\n# 3. Display first 10 rows\\nprint(bootstrap_sample.head(10))\\n              I0     PA500       HFS           DA           Area        A/DA  \\\\\\n102  2600.000000  0.200538  0.208043  1063.441427  174480.476200  164.071543'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 5}, page_content='print(bootstrap_sample.head(10))\\n              I0     PA500       HFS           DA           Area        A/DA  \\\\\\n102  2600.000000  0.200538  0.208043  1063.441427  174480.476200  164.071543   \\n51    274.993396  0.147131  0.137532    66.457943    1217.415651   18.318588   \\n92   1800.000000  0.091979  0.205251   362.863321   15021.553890   41.397278   \\n14    485.668806  0.230209  0.134041   253.893699    8135.968359   32.044783   \\n71   1385.664721  0.092328  0.089361   202.480044    8785.028733   43.387134   \\n60    197.000000  0.132645  0.074002    33.460653     409.647141   12.242652   \\n20    500.000000  0.192684  0.194779   144.688578    3055.012963   21.114403   \\n102  2600.000000  0.200538  0.208043  1063.441427  174480.476200  164.071543   \\n82   1647.939811  0.080983  0.086568   576.770376   11852.485060   20.549747   \\n86   2100.000000  0.121649  0.377689   450.551667   35671.606290   79.173176   \\n         Max IP          DR            P  \\n102  418.687286  977.552367  2664.583623'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 5}, page_content='86   2100.000000  0.121649  0.377689   450.551667   35671.606290   79.173176   \\n         Max IP          DR            P  \\n102  418.687286  977.552367  2664.583623  \\n51    40.849678   52.421008   327.558639  \\n92   217.833969  290.203640  1893.663712  \\n14    64.855446  245.470531   541.363975  \\n71   143.092194  143.257780  1524.609204  \\n60    26.992807   19.773813   231.783788  \\n20    96.563370  107.751103   542.897089  \\n102  418.687286  977.552367  2664.583623  \\n82   111.435913  565.902910  1402.877737  \\n86   436.099640  113.198570  2461.450497  \\n# Q4\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score, confusion_matrix\\n# Load dataset\\ndf = pd.read_csv(\"btissue.csv\")\\n# 1. Separate predictors and target\\nIn\\xa0[11]:\\nIn\\xa0[12]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n6/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 6}, page_content='X = df.iloc[:, :-1]\\ny = df.iloc[:, -1]\\n# 2. Holdout split\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=42\\n)\\n# 3. Train Random Forest\\nmodel = RandomForestClassifier(random_state=42)\\nmodel.fit(X_train, y_train)\\n# 4. Evaluation\\ny_pred = model.predict(X_test)\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\nprint(\"Confusion Matrix:\\\\n\", confusion_matrix(y_test, y_pred))\\nAccuracy: 0.7727272727272727\\nConfusion Matrix:\\n [[3 0 0 0 0 0]\\n [0 6 0 0 0 0]\\n [0 0 4 0 0 0]\\n [0 0 0 0 0 2]\\n [0 0 0 0 2 2]\\n [0 0 0 0 1 2]]\\n# Q5\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.metrics import mean_squared_error, r2_score\\n# Load dataset\\ndf = pd.read_csv(\"auto_mpg.csv\")\\n# 1. Remove rows with missing values\\ndf = df.dropna()\\ndf = pd.get_dummies(df, drop_first=True)\\n# 3. Separate predictors and target\\nX = df.drop(\"mpg\", axis=1)\\ny = df[\"mpg\"]'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 6}, page_content='# 1. Remove rows with missing values\\ndf = df.dropna()\\ndf = pd.get_dummies(df, drop_first=True)\\n# 3. Separate predictors and target\\nX = df.drop(\"mpg\", axis=1)\\ny = df[\"mpg\"]\\n# 4. Train-test split (80% train, 20% test)\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=42\\n)\\n# 5. Train Linear Regression model\\nmodel = LinearRegression()\\nmodel.fit(X_train, y_train)\\n# 6. Predict on test data\\ny_pred = model.predict(X_test)\\n# 7. Evaluate the model\\nIn\\xa0[17]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n7/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 7}, page_content='print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\\nprint(\"R2 Score:\", r2_score(y_test, y_pred))\\nMean Squared Error: 16.958285786091167\\nR2 Score: 0.6677489811118411\\n# Q6\\nimport pandas as pd\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.metrics import v_measure_score, silhouette_score\\nfrom sklearn.preprocessing import LabelEncoder\\n# Load dataset\\ndf = pd.read_csv(\"Dataset_spine.csv\")\\ndf = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\\n# 1. Separate predictors and class column\\nX = df.iloc[:, :-1]        # Exclude class_att from predictors\\ny = df.iloc[:, -1]         # Keep class_att ONLY for evaluation\\n# 2. Encode class labels (required for v-measure)\\nle = LabelEncoder()\\ny_encoded = le.fit_transform(y)\\n# 3. Apply K-Means clustering\\nkmeans = KMeans(n_clusters=3, random_state=123)\\ny_pred = kmeans.fit_predict(X)\\n# 4. Compute quality measures\\nprint(\"V-measure Score:\", v_measure_score(y_encoded, y_pred))\\nprint(\"Silhouette Score:\", silhouette_score(X, y_pred))'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 7}, page_content='y_pred = kmeans.fit_predict(X)\\n# 4. Compute quality measures\\nprint(\"V-measure Score:\", v_measure_score(y_encoded, y_pred))\\nprint(\"Silhouette Score:\", silhouette_score(X, y_pred))\\nV-measure Score: 0.24233882112188337\\nSilhouette Score: 0.3776387213379063\\nC:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\site-packages\\\\sklearn\\\\cluster\\\\_kmeans.py:1419: UserW\\narning: KMeans is known to have a memory leak on Windows with MKL, when there are \\nless chunks than available threads. You can avoid it by setting the environment v\\nariable OMP_NUM_THREADS=2.\\n  warnings.warn(\\nimport pandas as pd\\ndf = pd.read_csv(\\'Dataset_spine.csv\\')\\ndf\\nIn\\xa0[23]:\\nIn\\xa0[21]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n8/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 8}, page_content='\\uedd9\\n\\uedda\\nCol1\\nCol2\\nCol3\\nCol4\\nCol5\\nCol6\\nCol7\\nCo\\n0\\n63.027817\\n22.552586\\n39.609117\\n40.475232\\n98.672917\\n-0.254400\\n0.744503\\n12.56\\n1\\n39.056951\\n10.060991\\n25.015378\\n28.995960\\n114.405425\\n4.564259\\n0.415186\\n12.88\\n2\\n68.832021\\n22.218482\\n50.092194\\n46.613539\\n105.985135\\n-3.530317\\n0.474889\\n26.83\\n3\\n69.297008\\n24.652878\\n44.311238\\n44.644130\\n101.868495\\n11.211523\\n0.369345\\n23.56\\n4\\n49.712859\\n9.652075\\n28.317406\\n40.060784\\n108.168725\\n7.918501\\n0.543360\\n35.49\\n...\\n...\\n...\\n...\\n...\\n...\\n...\\n...\\n305\\n47.903565\\n13.616688\\n36.000000\\n34.286877\\n117.449062\\n-4.245395\\n0.129744\\n7.84\\n306\\n53.936748\\n20.721496\\n29.220534\\n33.215251\\n114.365845\\n-0.421010\\n0.047913\\n19.19\\n307\\n61.446597\\n22.694968\\n46.170347\\n38.751628\\n125.670725\\n-2.707880\\n0.081070\\n16.20\\n308\\n45.252792\\n8.693157\\n41.583126\\n36.559635\\n118.545842\\n0.214750\\n0.159251\\n14.73\\n309\\n33.841641\\n5.073991\\n36.641233\\n28.767649\\n123.945244\\n-0.199249\\n0.674504\\n19.38\\n310 rows  14 columns\\n \\nOut[21]:\\nIn\\xa0[\\xa0]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:24:41+00:00', 'source': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Model Traini (4) - JupyterLab.pdf', 'total_pages': 9, 'format': 'PDF 1.4', 'title': 'Model Traini (4) - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:24:41+00:00', 'trapped': '', 'modDate': \"D:20251219052441+00'00'\", 'creationDate': \"D:20251219052441+00'00'\", 'page': 8}, page_content='0.214750\\n0.159251\\n14.73\\n309\\n33.841641\\n5.073991\\n36.641233\\n28.767649\\n123.945244\\n-0.199249\\n0.674504\\n19.38\\n310 rows  14 columns\\n \\nOut[21]:\\nIn\\xa0[\\xa0]:\\n12/19/25, 10:54 AM\\nModel Training and Evaluation\\nlocalhost:8889/lab/tree/Documents/College-MLC/Model Training and Evaluation.ipynb\\n9/9'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 0}, page_content='# Q1\\nimport pandas as pd\\nl1 = [10, 20, 30, 40, 50]\\nidx = [\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\']\\ns = pd.Series(l1, idx)\\n# (a) First 3 elements\\nprint(s.head(3))\\n# (b) Element at index \\'c\\'\\nprint(s[\\'c\\'])\\na    10\\nb    20\\nc    30\\ndtype: int64\\n30\\n# Q2\\nimport numpy as np\\nimport pandas as pd\\narr = np.random.randint(1, 101, size=10)\\ns2 = pd.Series(arr)\\n# (a) Max, Min, Mean\\nprint(\"Max:\", s2.max())\\nprint(\"Min:\", s2.min())\\nprint(\"Mean:\", s2.mean())\\n# (b) Square each element\\ns2_squared = s2.apply(lambda x: x**2)\\nprint(s2_squared)\\nMax: 98\\nMin: 1\\nMean: 37.4\\n0    3969\\n1    9604\\n2      64\\n3       1\\n4    1681\\n5     576\\n6    3136\\n7     729\\n8     225\\n9    1681\\ndtype: int64\\n# Q3\\ndata = {\\'Math\\': 85, \\'Science\\': 90, \\'English\\': 88}\\ns = pd.Series(data)\\nprint(s[\\'Science\\'])\\n90\\nIn\\xa0[1]:\\nIn\\xa0[2]:\\nIn\\xa0[6]:\\n12/19/25, 10:31 AM\\nNumpy_&_Pandas\\nlocalhost:8889/lab/tree/Documents/College-MLC/Numpy_%26_Pandas.ipynb\\n1/6'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 1}, page_content=\"# Q4\\ns4 = pd.Series([5, np.nan, 8, np.nan, 12])\\n# (a) Check missing values\\nprint(s4.isna())\\n# (b) Forward fill\\nprint(s4.fillna(method='ffill'))\\n# (c) Drop missing values\\nprint(s4.dropna())\\n0    False\\n1     True\\n2    False\\n3     True\\n4    False\\ndtype: bool\\n0     5.0\\n1     5.0\\n2     8.0\\n3     8.0\\n4    12.0\\ndtype: float64\\n0     5.0\\n2     8.0\\n4    12.0\\ndtype: float64\\nC:\\\\Users\\\\drnay\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_10328\\\\2187642790.py:9: FutureWarning: \\nSeries.fillna with 'method' is deprecated and will raise in a future version. Use \\nobj.ffill() or obj.bfill() instead.\\n  print(s4.fillna(method='ffill'))\\n# Q5\\ndata = {\\n    'Name': ['Amit', 'Riya', 'John', 'Sara'],\\n    'Age': [25, 30, 22, 28],\\n    'Salary': [50000, 60000, 55000, 65000]\\n}\\ndf = pd.DataFrame(data)\\n# (a) Age > 25\\nprint(df[df['Age'] > 25])\\n# (b) Salary between 55,000 and 65,000\\nprint(df[(df['Salary'] >= 55000) & (df['Salary'] <= 65000)])\\n   Name  Age  Salary\\n1  Riya   30   60000\\n3  Sara   28   65000\\n   Name  Age  Salary\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 1}, page_content=\"# (b) Salary between 55,000 and 65,000\\nprint(df[(df['Salary'] >= 55000) & (df['Salary'] <= 65000)])\\n   Name  Age  Salary\\n1  Riya   30   60000\\n3  Sara   28   65000\\n   Name  Age  Salary\\n1  Riya   30   60000\\n2  John   22   55000\\n3  Sara   28   65000\\n# Q6\\ndata = {\\nIn\\xa0[7]:\\nIn\\xa0[9]:\\nIn\\xa0[10]:\\n12/19/25, 10:31 AM\\nNumpy_&_Pandas\\nlocalhost:8889/lab/tree/Documents/College-MLC/Numpy_%26_Pandas.ipynb\\n2/6\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 2}, page_content=\"'Department': ['HR','IT','HR','IT','Finance'],\\n    'Employee': ['A','B','C','D','E'],\\n    'Salary': [40000, 50000, 42000, 55000, 60000]\\n}\\ndf2 = pd.DataFrame(data)\\n# (a) Average salary per department\\nprint(df2.groupby('Department')['Salary'].mean())\\n# (b) Employee count per department\\nprint(df2.groupby('Department')['Employee'].count())\\n# (c) Sort by Salary (ascending)\\nprint(df2.sort_values(by='Salary'))\\n# (d) Sort by Department, then Salary (descending)\\nprint(df2.sort_values(by=['Department', 'Salary'], ascending=[True, False]))\\nDepartment\\nFinance    60000.0\\nHR         41000.0\\nIT         52500.0\\nName: Salary, dtype: float64\\nDepartment\\nFinance    1\\nHR         2\\nIT         2\\nName: Employee, dtype: int64\\n  Department Employee  Salary\\n0         HR        A   40000\\n2         HR        C   42000\\n1         IT        B   50000\\n3         IT        D   55000\\n4    Finance        E   60000\\n  Department Employee  Salary\\n4    Finance        E   60000\\n2         HR        C   42000\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 2}, page_content=\"1         IT        B   50000\\n3         IT        D   55000\\n4    Finance        E   60000\\n  Department Employee  Salary\\n4    Finance        E   60000\\n2         HR        C   42000\\n0         HR        A   40000\\n3         IT        D   55000\\n1         IT        B   50000\\n# Q7\\ndata = {\\n    'Name': ['Amit', 'Riya', 'Amit', 'John', 'Riya'],\\n    'Age': [25, 30, 25, 22, 30]\\n}\\ndf3 = pd.DataFrame(data)\\n# (a) Display duplicate rows\\nprint(df3[df3.duplicated()])\\n# (b) Drop duplicates\\nprint(df3.drop_duplicates(keep='first'))\\nprint(df3.drop_duplicates(keep='last'))\\nprint(df3.drop_duplicates(keep=False))\\n# (c) Drop duplicates based on Name\\nprint(df3.drop_duplicates(subset=['Name']))\\nIn\\xa0[11]:\\n12/19/25, 10:31 AM\\nNumpy_&_Pandas\\nlocalhost:8889/lab/tree/Documents/College-MLC/Numpy_%26_Pandas.ipynb\\n3/6\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 3}, page_content=\"# (d) Count duplicate rows\\nprint(df3.duplicated().sum())\\n# (e) Unique names\\nprint(df3['Name'].unique())\\n   Name  Age\\n2  Amit   25\\n4  Riya   30\\n   Name  Age\\n0  Amit   25\\n1  Riya   30\\n3  John   22\\n   Name  Age\\n2  Amit   25\\n3  John   22\\n4  Riya   30\\n   Name  Age\\n3  John   22\\n   Name  Age\\n0  Amit   25\\n1  Riya   30\\n3  John   22\\n2\\n['Amit' 'Riya' 'John']\\n# Q8\\ndata = {\\n    'Name': ['Amit', 'Riya', 'John', None],\\n    'Age': [25, np.nan, 22, np.nan],\\n    'Salary': [50000, 60000, np.nan, np.nan]\\n}\\ndf4 = pd.DataFrame(data)\\n# (a) Detect missing values\\nprint(df4.isna())\\n# (b) Count missing values per column\\nprint(df4.isna().sum())\\n# (c) Drop rows\\nprint(df4.dropna())                     # Any NaN\\nprint(df4.dropna(how='all'))            # All NaN\\nprint(df4.dropna(subset=['Age','Salary']))\\n# (d) Fill missing values\\nprint(df4.fillna(0))\\nprint(df4.fillna({'Name':'Unknown'}))\\nprint(df4.fillna(df4.mean(numeric_only=True)))\\nprint(df4.fillna(method='ffill'))\\nprint(df4.fillna(method='bfill'))\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 3}, page_content='# (d) Fill missing values\\nprint(df4.fillna(0))\\nprint(df4.fillna({\\'Name\\':\\'Unknown\\'}))\\nprint(df4.fillna(df4.mean(numeric_only=True)))\\nprint(df4.fillna(method=\\'ffill\\'))\\nprint(df4.fillna(method=\\'bfill\\'))\\nprint(df4.interpolate())\\n# (e) Forward fill vs Interpolation\\nprint(\"Forward Fill:\\\\n\", df4.fillna(method=\\'ffill\\'))\\nprint(\"Interpolation:\\\\n\", df4.interpolate())\\nIn\\xa0[12]:\\n12/19/25, 10:31 AM\\nNumpy_&_Pandas\\nlocalhost:8889/lab/tree/Documents/College-MLC/Numpy_%26_Pandas.ipynb\\n4/6'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 4}, page_content='Name    Age  Salary\\n0  False  False   False\\n1  False   True   False\\n2  False  False    True\\n3   True   True    True\\nName      1\\nAge       2\\nSalary    2\\ndtype: int64\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya   NaN  60000.0\\n2  John  22.0      NaN\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya   0.0  60000.0\\n2  John  22.0      0.0\\n3     0   0.0      0.0\\n      Name   Age   Salary\\n0     Amit  25.0  50000.0\\n1     Riya   NaN  60000.0\\n2     John  22.0      NaN\\n3  Unknown   NaN      NaN\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  23.5  60000.0\\n2  John  22.0  55000.0\\n3  None  23.5  55000.0\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  25.0  60000.0\\n2  John  22.0  60000.0\\n3  John  22.0  60000.0\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  22.0  60000.0\\n2  John  22.0      NaN\\n3  None   NaN      NaN\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 4}, page_content='3  John  22.0  60000.0\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  22.0  60000.0\\n2  John  22.0      NaN\\n3  None   NaN      NaN\\n   Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  23.5  60000.0\\n2  John  22.0  60000.0\\n3  None  22.0  60000.0\\nForward Fill:\\n    Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  25.0  60000.0\\n2  John  22.0  60000.0\\n3  John  22.0  60000.0\\nInterpolation:\\n    Name   Age   Salary\\n0  Amit  25.0  50000.0\\n1  Riya  23.5  60000.0\\n2  John  22.0  60000.0\\n3  None  22.0  60000.0\\n12/19/25, 10:31 AM\\nNumpy_&_Pandas\\nlocalhost:8889/lab/tree/Documents/College-MLC/Numpy_%26_Pandas.ipynb\\n5/6'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 5}, page_content=\"C:\\\\Users\\\\drnay\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_10328\\\\4220938775.py:25: FutureWarnin\\ng: DataFrame.fillna with 'method' is deprecated and will raise in a future versio\\nn. Use obj.ffill() or obj.bfill() instead.\\n  print(df4.fillna(method='ffill'))\\nC:\\\\Users\\\\drnay\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_10328\\\\4220938775.py:26: FutureWarnin\\ng: DataFrame.fillna with 'method' is deprecated and will raise in a future versio\\nn. Use obj.ffill() or obj.bfill() instead.\\n  print(df4.fillna(method='bfill'))\\nC:\\\\Users\\\\drnay\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_10328\\\\4220938775.py:27: FutureWarnin\\ng: DataFrame.interpolate with object dtype is deprecated and will raise in a futu\\nre version. Call obj.infer_objects(copy=False) before interpolating instead.\\n  print(df4.interpolate())\\nC:\\\\Users\\\\drnay\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_10328\\\\4220938775.py:30: FutureWarnin\\ng: DataFrame.fillna with 'method' is deprecated and will raise in a future versio\\nn. Use obj.ffill() or obj.bfill() instead.\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:01:19+00:00', 'source': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'file_path': 'data\\\\pdf\\\\Numpy_&_Pand - JupyterLab.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': 'Numpy_&_Pand - JupyterLab', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-19T05:01:19+00:00', 'trapped': '', 'modDate': \"D:20251219050119+00'00'\", 'creationDate': \"D:20251219050119+00'00'\", 'page': 5}, page_content='g: DataFrame.fillna with \\'method\\' is deprecated and will raise in a future versio\\nn. Use obj.ffill() or obj.bfill() instead.\\n  print(\"Forward Fill:\\\\n\", df4.fillna(method=\\'ffill\\'))\\nC:\\\\Users\\\\drnay\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_10328\\\\4220938775.py:31: FutureWarnin\\ng: DataFrame.interpolate with object dtype is deprecated and will raise in a futu\\nre version. Call obj.infer_objects(copy=False) before interpolating instead.\\n  print(\"Interpolation:\\\\n\", df4.interpolate())\\n \\nIn\\xa0[\\xa0]:\\n12/19/25, 10:31 AM\\nNumpy_&_Pandas\\nlocalhost:8889/lab/tree/Documents/College-MLC/Numpy_%26_Pandas.ipynb\\n6/6')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = split_documents(pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9cac7c-75c2-4b10-9bb3-3cc4347974b1",
   "metadata": {},
   "source": [
    "## Embeddings and VectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "153d5fa9-e266-4417-be60-3158734e1ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (5.2.2)\n",
      "Requirement already satisfied: langchain-chroma in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langchain-huggingface) (0.36.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langchain-huggingface) (1.2.6)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langchain-huggingface) (0.22.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2026.1.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.15.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.12.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.4.2)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from sentence-transformers) (4.57.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from sentence-transformers) (2.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from sentence-transformers) (1.17.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2026.1.15)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: chromadb<2.0.0,>=1.3.5 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from langchain-chroma) (1.4.1)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.4.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.40.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.50.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.21.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (35.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.2.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (14.3.2)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.26.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.6.3)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from build>=1.0.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from build>=1.0.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.4.6)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.30.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.10)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (25.12.19)\n",
      "Requirement already satisfied: protobuf in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (6.33.5)\n",
      "Requirement already satisfied: sympy in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.60b1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.1.2)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.2.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (16.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.5.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.3.1)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\drnay\\documents\\ai engg\\rag_pipeline_env\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: C:\\Users\\drnay\\Documents\\AI Engg\\rag_pipeline_env\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-huggingface sentence-transformers langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd5dfb24-42a2-4b0b-bf72-06b4f9ff3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "212732e8-5ded-4cde-aadd-ab0a7c84bd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x1cf3c8717f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "## initialize the embedding manager\n",
    "\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68531e5-a529-402f-ad6d-4dced97ec72e",
   "metadata": {},
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b77cd9d-0c94-4bd1-8760-17b4fa34e834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error initializing the vector store: Database error: error returned from database: (code: 1) no such table: tenants\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Database error: error returned from database: (code: 1) no such table: tenants",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     90\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError adding documents to the vector store: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m vectorstore = \u001b[43mVectorStore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m vectorstore\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVectorStore.__init__\u001b[39m\u001b[34m(self, collection_name, persist_directory)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mself\u001b[39m.collection = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mVectorStore._initialize_store\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# Create persitent ChromaDB client\u001b[39;00m\n\u001b[32m     25\u001b[39m     os.makedirs(\u001b[38;5;28mself\u001b[39m.persist_directory, exist_ok = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28mself\u001b[39m.client = \u001b[43mchromadb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPersistentClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# Get or create collection\u001b[39;00m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mself\u001b[39m.collection = \u001b[38;5;28mself\u001b[39m.client.get_or_create_collection(\n\u001b[32m     30\u001b[39m         name = \u001b[38;5;28mself\u001b[39m.collection_name,\n\u001b[32m     31\u001b[39m         metadata = {\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPDF Document embeddings for RAG\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     32\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\AI Engg\\rag_pipeline_env\\Lib\\site-packages\\chromadb\\__init__.py:216\u001b[39m, in \u001b[36mPersistentClient\u001b[39m\u001b[34m(path, settings, tenant, database)\u001b[39m\n\u001b[32m    213\u001b[39m tenant = \u001b[38;5;28mstr\u001b[39m(tenant)\n\u001b[32m    214\u001b[39m database = \u001b[38;5;28mstr\u001b[39m(database)\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClientCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\AI Engg\\rag_pipeline_env\\Lib\\site-packages\\chromadb\\api\\client.py:101\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, tenant, database, settings)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Create an admin client for verifying that databases and tenants exist\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;28mself\u001b[39m._admin_client = AdminClient.from_system(\u001b[38;5;28mself\u001b[39m._system)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_tenant_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28mself\u001b[39m._submit_client_start_event()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\AI Engg\\rag_pipeline_env\\Lib\\site-packages\\chromadb\\api\\client.py:485\u001b[39m, in \u001b[36mClient._validate_tenant_database\u001b[39m\u001b[34m(self, tenant, database)\u001b[39m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# Propagate ChromaErrors\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ChromaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    487\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    488\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not connect to tenant \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtenant\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Are you sure it exists?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    489\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\AI Engg\\rag_pipeline_env\\Lib\\site-packages\\chromadb\\api\\client.py:478\u001b[39m, in \u001b[36mClient._validate_tenant_database\u001b[39m\u001b[34m(self, tenant, database)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_tenant_database\u001b[39m(\u001b[38;5;28mself\u001b[39m, tenant: \u001b[38;5;28mstr\u001b[39m, database: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_admin_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tenant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    481\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCould not connect to a Chroma server. Are you sure it is running?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    482\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\AI Engg\\rag_pipeline_env\\Lib\\site-packages\\chromadb\\api\\client.py:535\u001b[39m, in \u001b[36mAdminClient.get_tenant\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_tenant\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Tenant:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tenant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\AI Engg\\rag_pipeline_env\\Lib\\site-packages\\chromadb\\api\\rust.py:174\u001b[39m, in \u001b[36mRustBindingsAPI.get_tenant\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_tenant\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Tenant:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     tenant = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tenant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Tenant(name=tenant.name)\n",
      "\u001b[31mInternalError\u001b[39m: Database error: error returned from database: (code: 1) no such table: tenants"
     ]
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Messages document embeddings in a ChromaDB Vector Store\"\"\"\n",
    "\n",
    "    def __init__(self, collection_name = \"pdf_documents\", persist_directory: str = \"data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "\n",
    "        Args:\n",
    "            collection_name: Name of the chromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory  = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize the ChromaDB client and collection\"\"\"\n",
    "\n",
    "        try:\n",
    "            # Create persitent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok = True)\n",
    "            self.client = chromadb.PersistentClient(path = self.persist_directory)\n",
    "\n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata = {\"description\": \"PDF Document embeddings for RAG\"}\n",
    "            )\n",
    "\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing the vector store: {e}\")\n",
    "            raise\n",
    "            \n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "\n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "\n",
    "        if(len(documents) != len(embeddings)):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "\n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique id\n",
    "            doc_id  = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            # Perpare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata[\"doc_index\"] = i\n",
    "            metadata[\"content_length\"] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids = ids,\n",
    "                embeddings = embeddings_list,\n",
    "                metadatas = metadatas,\n",
    "                documents = documents_text\n",
    "            )\n",
    "\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to the vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "vectorstore = VectorStore()\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7334dfe4-5184-4335-95b7-be33ff61a529",
   "metadata": {},
   "source": [
    "## Extract the text and coverting them to Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e870a7-0128-4340-a8d5-01487de3c9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 62 texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b67ba67a38403c8560fabd9a2b0557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (62, 384)\n",
      "Adding 62 documents to vector store...\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 52\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 53\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 54\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 55\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 56\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 57\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 58\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 59\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 60\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 61\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 62\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 63\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 64\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 65\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 66\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 67\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 68\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 69\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 70\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 71\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 72\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 73\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 74\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 75\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 76\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 77\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 78\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 79\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 80\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 81\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 82\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 83\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 84\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 85\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 86\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 87\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 88\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 89\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 90\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 91\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 92\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 93\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 94\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 95\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 96\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 97\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 98\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 99\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 100\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 101\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 102\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 103\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 104\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 105\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 106\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 107\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 108\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 109\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 110\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 111\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 112\n",
      "Successfully added 62 documents to vector store\n",
      "Total documents in collection: 113\n"
     ]
    }
   ],
   "source": [
    " # Convert the text to embeddings\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "\n",
    "# Genrate the embeddings\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "# Store in the vector db\n",
    "vectorstore.add_documents(chunks, embeddings)\n",
    "\n",
    "# This is the end of the ingestion pipeline, after this will be the start of retrieval pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03c75af-62e7-45d3-a458-a042d532e461",
   "metadata": {},
   "source": [
    "## Retriever Pipeline from Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e63c08c1-0bb1-457d-b9de-b56c294dcf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query based retrieval from the vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "\n",
    "        Args:\n",
    "            vector_store = vector store containing document embeddings\n",
    "            embedding_manager = Manager for generating query emebeddings\n",
    "        \"\"\"\n",
    "\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for the query\n",
    "\n",
    "        Args:\n",
    "            query: the search query \n",
    "            top_k: Number of top results to return \n",
    "            score_threshold: Minimum similarity score threshold\n",
    "\n",
    "        returns:\n",
    "            list of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Retrieving documents for query {query}\")\n",
    "        print(f\"Top k: {top_k}, Score threshold: {score_threshold}\")\n",
    "\n",
    "        query_embeddings = self.embedding_manager.generate_embeddings([query])[0]\n",
    "\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings = [query_embeddings.tolist()],\n",
    "                n_results = top_k\n",
    "            )\n",
    "\n",
    "            retrieved_docs = []\n",
    "\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    \n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever = RAGRetriever(vectorstore,embedding_manager)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2bf8592-7106-4343-a5bb-418cfd9f8c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x1cf3f953e00>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b6e8e04-4de8-4dcb-b395-a3a1796ffbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query What Does Influcraft Do?\n",
      "Top k: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cbf8bc528a4cff977b6c82159893b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 0 documents (after filtering)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"What Does Influcraft Do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d269dc9-4c96-44b3-b4e9-58a7224a41b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RAG Pipeline)",
   "language": "python",
   "name": "rag_pipeline_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
